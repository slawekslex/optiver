{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4deb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5.sklearn import PermutationImportance \n",
    "import eli5\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import lightgbm as lgb\n",
    "from optiver_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5aac6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_feather('train_182cols.feather')\n",
    "test_df =pd.read_feather('test_182cols.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "80a555da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe_np(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "def feval_rmspe(y_true, y_pred):\n",
    "    return 'RMSPE', round(rmspe_np(y_true = y_true, y_pred = y_pred), 5), False\n",
    "\n",
    "params_lgbm = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.01,\n",
    "        'objective': 'regression',\n",
    "        'metric': 'None',\n",
    "        'max_depth': -1,\n",
    "        'n_jobs': -1,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'lambda_l2': 1,\n",
    "        'verbose': -1,\n",
    "        'early_stopping_rounds': 500,\n",
    "        #'bagging_freq': 5\n",
    "        #'device_type':'gpu'\n",
    "}\n",
    "\n",
    "def train_models(train, to_keep = None, with_importance=False):\n",
    "    # Hyperparammeters (optimized)\n",
    "    seed = 29\n",
    "    \n",
    "    \n",
    "    # Split features and target\n",
    "    if to_keep: x = train[to_keep]\n",
    "    else: x = train.drop(['row_id', 'target', 'time_id'], axis = 1)\n",
    "    y = train['target']\n",
    "    # Transform stock id to a numeric value\n",
    "    #x['stock_id'] = x['stock_id'].astype(int)\n",
    "    models =[]\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = GroupKFold()\n",
    "    # Iterate through each fold\n",
    "    importances = []\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(x, groups = train.time_id)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x.iloc[trn_ind], x.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train, y_train, weight = train_weights)\n",
    "        val_dataset = lgb.Dataset(x_val, y_val, weight = val_weights)\n",
    "        \n",
    "        weights_1 = 1/np.square(y_train)\n",
    "        weights_2 = 1/np.square(y_val)\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params_lgbm, \n",
    "                                  random_state = 1976, \n",
    "\n",
    "                                  device_type = 'gpu',\n",
    "                                  n_estimators= 5000)\n",
    "        model.fit(x_train, y_train, \n",
    "              eval_set=[(x_val, y_val)], \n",
    "              eval_metric = feval_rmspe,\n",
    "              sample_weight=weights_1,\n",
    "              eval_sample_weight=[weights_2],\n",
    "              verbose=500,\n",
    "              categorical_feature = ['stock_id']\n",
    "                 )\n",
    "        models.append(model)\n",
    "        oof_predictions[val_ind] = model.predict(x_val)\n",
    "        if with_importance:\n",
    "            perm = PermutationImportance(model, random_state=42)\n",
    "            perm.fit(x_val, y_val)\n",
    "            importances.append(perm.feature_importances_)\n",
    "    rmspe_score = rmspe_np(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    # Return test predictions\n",
    "    return models, importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "66b099dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/engine.py:182: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1996: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1999: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['stock_id']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1727: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1460: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's RMSPE: 0.22068\n",
      "[1000]\tvalid_0's RMSPE: 0.22\n",
      "Early stopping, best iteration is:\n",
      "[802]\tvalid_0's RMSPE: 0.21975\n",
      "Training fold 2\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's RMSPE: 0.22242\n",
      "Early stopping, best iteration is:\n",
      "[484]\tvalid_0's RMSPE: 0.22235\n",
      "Training fold 3\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's RMSPE: 0.2229\n",
      "[1000]\tvalid_0's RMSPE: 0.22069\n",
      "[1500]\tvalid_0's RMSPE: 0.22014\n",
      "[2000]\tvalid_0's RMSPE: 0.22008\n",
      "[2500]\tvalid_0's RMSPE: 0.21995\n",
      "Early stopping, best iteration is:\n",
      "[2469]\tvalid_0's RMSPE: 0.21995\n",
      "Training fold 4\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's RMSPE: 0.22359\n",
      "[1000]\tvalid_0's RMSPE: 0.22264\n",
      "Early stopping, best iteration is:\n",
      "[999]\tvalid_0's RMSPE: 0.22254\n",
      "Training fold 5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's RMSPE: 0.22169\n",
      "[1000]\tvalid_0's RMSPE: 0.22107\n",
      "Early stopping, best iteration is:\n",
      "[744]\tvalid_0's RMSPE: 0.22087\n",
      "Our out of folds RMSPE is 0.22109658834443383\n"
     ]
    }
   ],
   "source": [
    "models, feat_imps = train_models(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bfd63b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(models, columns):\n",
    "    test_pred = np.zeros(len(test_df))\n",
    "    for model in models:\n",
    "        pred = model.predict(test_df[columns]) \n",
    "        test_pred += pred /5\n",
    "\n",
    "    return  rmspe_np(test_df.target, test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2760ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_cols = [x for x in train_df.columns if x not in ['row_id', 'target', 'time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6d97e650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22334512233363665"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score(models, starting_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "85cdb23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 600), (100, 600), (200, 600), (300, 600), (400, 600), (500, 600)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows = list(zip(range(0,601,100), [600]*6))\n",
    "windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "dbc557d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_cols = [ 'log_return2_std_0_600',  'log_return_price_std_0_600', '5m_pred', 'stock_id'] \n",
    "minimal_cols += [f'time_emb{x}' for x in range(10)]\n",
    "minimal_cols +=['order_count_sum_0_600', 'seconds_in_bucket_size_0_600', 'size_sum_0_600']\n",
    "minimal_cols += [f'stock_emb{x}' for x in range(9)]\n",
    "minimal_cols += ['log_return1_std_0_600_min_time', 'log_return1_std_0_600_mean_time']\n",
    "\n",
    "minimal_cols +=['log_return1_std_0_600_min_stock', 'log_return1_std_0_600_mean_stock']\n",
    "minimal_cols += [f'{log_ret}_{a}_{b}' for a,b in windows for log_ret in ['log_return1_std']]\n",
    "\n",
    "minimal_cols += [f'price_spread_mean_0_600']\n",
    "minimal_cols += [f'log_return_price_std_{a}_{b}_mean_time' for a, b in windows]\n",
    "minimal_cols += [f'log_return_price_std_{a}_{b}_min_time' for a, b in windows]\n",
    "minimal_cols += ['total_volume_mean_0_600']\n",
    "len(minimal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "3ec9f0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_return2_std_0_600',\n",
       " 'log_return_price_std_0_600',\n",
       " '5m_pred',\n",
       " 'stock_id',\n",
       " 'time_emb0',\n",
       " 'time_emb1',\n",
       " 'time_emb2',\n",
       " 'time_emb3',\n",
       " 'time_emb4',\n",
       " 'time_emb5',\n",
       " 'time_emb6',\n",
       " 'time_emb7',\n",
       " 'time_emb8',\n",
       " 'time_emb9',\n",
       " 'order_count_sum_0_600',\n",
       " 'seconds_in_bucket_size_0_600',\n",
       " 'size_sum_0_600',\n",
       " 'log_return1_std_0_600_min_time',\n",
       " 'log_return1_std_0_600_mean_time',\n",
       " 'log_return1_std_0_600_min_stock',\n",
       " 'log_return1_std_0_600_mean_stock',\n",
       " 'log_return1_std_0_600',\n",
       " 'log_return1_std_100_600',\n",
       " 'log_return1_std_200_600',\n",
       " 'log_return1_std_300_600',\n",
       " 'log_return1_std_400_600',\n",
       " 'log_return1_std_500_600',\n",
       " 'price_spread_mean_0_600',\n",
       " 'log_return_price_std_0_600_mean_time',\n",
       " 'log_return_price_std_100_600_mean_time',\n",
       " 'log_return_price_std_200_600_mean_time',\n",
       " 'log_return_price_std_300_600_mean_time',\n",
       " 'log_return_price_std_400_600_mean_time',\n",
       " 'log_return_price_std_500_600_mean_time',\n",
       " 'log_return_price_std_0_600_min_time',\n",
       " 'log_return_price_std_100_600_min_time',\n",
       " 'log_return_price_std_200_600_min_time',\n",
       " 'log_return_price_std_300_600_min_time',\n",
       " 'log_return_price_std_400_600_min_time',\n",
       " 'log_return_price_std_500_600_min_time',\n",
       " 'total_volume_mean_0_600']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2a5b8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in feat_imp_df.max(axis=0).sort_values(ascending=False).index.to_list():\n",
    "#     if x not in minimal_cols: print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "05c75a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/engine.py:182: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1996: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1999: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['stock_id']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1727: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1460: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's RMSPE: 0.22049\n",
      "[1000]\tvalid_0's RMSPE: 0.22023\n",
      "Early stopping, best iteration is:\n",
      "[746]\tvalid_0's RMSPE: 0.21959\n",
      "Training fold 2\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's RMSPE: 0.22391\n",
      "[1000]\tvalid_0's RMSPE: 0.22685\n",
      "Early stopping, best iteration is:\n",
      "[514]\tvalid_0's RMSPE: 0.22385\n",
      "Training fold 3\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's RMSPE: 0.22282\n",
      "[1000]\tvalid_0's RMSPE: 0.21987\n",
      "[1500]\tvalid_0's RMSPE: 0.21905\n",
      "[2000]\tvalid_0's RMSPE: 0.21905\n",
      "Early stopping, best iteration is:\n",
      "[1583]\tvalid_0's RMSPE: 0.219\n",
      "Training fold 4\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's RMSPE: 0.22361\n",
      "[1000]\tvalid_0's RMSPE: 0.22285\n",
      "Early stopping, best iteration is:\n",
      "[870]\tvalid_0's RMSPE: 0.22275\n",
      "Training fold 5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l2 is set=1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\tvalid_0's RMSPE: 0.22264\n",
      "[1000]\tvalid_0's RMSPE: 0.22267\n",
      "Early stopping, best iteration is:\n",
      "[796]\tvalid_0's RMSPE: 0.22239\n",
      "Our out of folds RMSPE is 0.22152758451546478\n"
     ]
    }
   ],
   "source": [
    "models, imps = train_models(train_df, minimal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a89c6c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2231407111076792"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score(models, minimal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d93e301a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2216, 2232)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2216, 2232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "288b1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop  =pd.DataFrame(imps, columns = minimal_cols).max(axis=0).sort_values()[:1].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7bbdc890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_return2_std_0_600 log_return1_std_0_600 0.970282057943801\n",
      "log_return2_std_0_600 log_return1_std_100_600 0.9641458966476303\n",
      "log_return2_std_0_600 log_return1_std_200_600 0.9540069652041591\n",
      "5m_pred log_return1_std_100_600 0.9534987560166015\n",
      "5m_pred log_return1_std_200_600 0.9631501229739752\n",
      "5m_pred log_return1_std_300_600 0.9711535326423157\n",
      "5m_pred log_return1_std_400_600 0.9667020406285889\n",
      "log_return1_std_0_600_mean_time log_return_price_std_0_600_mean_time 0.9838662929929951\n",
      "log_return1_std_0_600_mean_time log_return_price_std_100_600_mean_time 0.9840205362498697\n",
      "log_return1_std_0_600_mean_time log_return_price_std_200_600_mean_time 0.9834728804881593\n",
      "log_return1_std_0_600_mean_time log_return_price_std_300_600_mean_time 0.9821428551607181\n",
      "log_return1_std_0_600_mean_time log_return_price_std_400_600_mean_time 0.9805363755189537\n",
      "log_return1_std_0_600_mean_time log_return_price_std_500_600_mean_time 0.9793468802257981\n",
      "log_return1_std_0_600 log_return1_std_100_600 0.9928527275972774\n",
      "log_return1_std_0_600 log_return1_std_200_600 0.9823892768026556\n",
      "log_return1_std_0_600 log_return1_std_300_600 0.9684434969365446\n",
      "log_return1_std_100_600 log_return1_std_200_600 0.9923715958456305\n",
      "log_return1_std_100_600 log_return1_std_300_600 0.9796211093848184\n",
      "log_return1_std_100_600 log_return1_std_400_600 0.9589638411976791\n",
      "log_return1_std_200_600 log_return1_std_300_600 0.9898803347144458\n",
      "log_return1_std_200_600 log_return1_std_400_600 0.9700110519305568\n",
      "log_return1_std_300_600 log_return1_std_400_600 0.9828475027441183\n",
      "log_return1_std_400_600 log_return1_std_500_600 0.9587064953636478\n",
      "price_spread_mean_0_600 price_spread_mean_100_600 0.9968608734411033\n",
      "price_spread_mean_0_600 price_spread_mean_200_600 0.9907862072776266\n",
      "price_spread_mean_0_600 price_spread_mean_300_600 0.9829478095888835\n",
      "price_spread_mean_0_600 price_spread_mean_400_600 0.9719018149436232\n",
      "price_spread_mean_0_600 price_spread_mean_500_600 0.9526812674004619\n",
      "price_spread_mean_100_600 price_spread_mean_200_600 0.9968013383646394\n",
      "price_spread_mean_100_600 price_spread_mean_300_600 0.9901888755307093\n",
      "price_spread_mean_100_600 price_spread_mean_400_600 0.9796608214769502\n",
      "price_spread_mean_100_600 price_spread_mean_500_600 0.9605736440810452\n",
      "price_spread_mean_200_600 price_spread_mean_300_600 0.9959307022042329\n",
      "price_spread_mean_200_600 price_spread_mean_400_600 0.9862947685551386\n",
      "price_spread_mean_200_600 price_spread_mean_500_600 0.967419884982542\n",
      "price_spread_mean_300_600 price_spread_mean_400_600 0.9933455967287852\n",
      "price_spread_mean_300_600 price_spread_mean_500_600 0.9746733799991312\n",
      "price_spread_mean_400_600 price_spread_mean_500_600 0.9852990238669606\n",
      "log_return_price_std_0_600_mean_time log_return_price_std_100_600_mean_time 0.999318559664734\n",
      "log_return_price_std_0_600_mean_time log_return_price_std_200_600_mean_time 0.9971239832590366\n",
      "log_return_price_std_0_600_mean_time log_return_price_std_300_600_mean_time 0.9939608609200478\n",
      "log_return_price_std_0_600_mean_time log_return_price_std_400_600_mean_time 0.9891373641409471\n",
      "log_return_price_std_0_600_mean_time log_return_price_std_500_600_mean_time 0.97876363464957\n",
      "log_return_price_std_100_600_mean_time log_return_price_std_200_600_mean_time 0.9989588669601429\n",
      "log_return_price_std_100_600_mean_time log_return_price_std_300_600_mean_time 0.9966422970066887\n",
      "log_return_price_std_100_600_mean_time log_return_price_std_400_600_mean_time 0.9924883833058112\n",
      "log_return_price_std_100_600_mean_time log_return_price_std_500_600_mean_time 0.9828997501139015\n",
      "log_return_price_std_200_600_mean_time log_return_price_std_300_600_mean_time 0.9988348501300098\n",
      "log_return_price_std_200_600_mean_time log_return_price_std_400_600_mean_time 0.9956747127551914\n",
      "log_return_price_std_200_600_mean_time log_return_price_std_500_600_mean_time 0.9870123327606001\n",
      "log_return_price_std_300_600_mean_time log_return_price_std_400_600_mean_time 0.997798203405148\n",
      "log_return_price_std_300_600_mean_time log_return_price_std_500_600_mean_time 0.9902128943275144\n",
      "log_return_price_std_400_600_mean_time log_return_price_std_500_600_mean_time 0.9939855020055536\n",
      "log_return_price_std_0_600_min_time log_return_price_std_100_600_min_time 0.9887388999448486\n",
      "log_return_price_std_0_600_min_time log_return_price_std_200_600_min_time 0.9634252896820854\n",
      "log_return_price_std_100_600_min_time log_return_price_std_200_600_min_time 0.9754932119605791\n",
      "log_return_price_std_200_600_min_time log_return_price_std_300_600_min_time 0.9534570557030397\n"
     ]
    }
   ],
   "source": [
    "C = train_df[minimal_cols].corr()\n",
    "for i in range(len(C)):\n",
    "    for j in range(i+1, len(C)):\n",
    "        if C.iloc[i,j] > .95:\n",
    "            print(C.columns[i], C.columns[j], C.iloc[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "5334dddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8839656981232888"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8b30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python38564bitfastaicondad52d12c5a30a4725bf9d3e235cf1271c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
