{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "center-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "russian-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "physical-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_with_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "alpine-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train):\n",
    "    # Hyperparammeters (optimized)\n",
    "    seed = 29\n",
    "    params = {\n",
    "        'learning_rate': 0.1,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 4,\n",
    "        'seed': seed,\n",
    "        'feature_fraction_seed': seed,\n",
    "        'bagging_seed': seed,\n",
    "        'drop_seed': seed,\n",
    "        'data_random_seed': seed,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "    }   \n",
    "    \n",
    "    # Split features and target\n",
    "    x = train.drop(['row_id', 'target', 'time_id'], axis = 1)\n",
    "    y = train['target']\n",
    "    # Transform stock id to a numeric value\n",
    "    x['stock_id'] = x['stock_id'].astype(int)\n",
    "    models =[]\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = KFold(n_splits = 10, random_state = 1111, shuffle = True)\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(x)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x.iloc[trn_ind], x.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train, y_train, weight = train_weights, categorical_feature = ['stock_id'])\n",
    "        val_dataset = lgb.Dataset(x_val, y_val, weight = val_weights, categorical_feature = ['stock_id'])\n",
    "        model = lgb.train(params = params, \n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          num_boost_round = 3000, \n",
    "                          early_stopping_rounds = 25, \n",
    "                          verbose_eval = 100,\n",
    "                          feval = feval_rmspe)\n",
    "        models.append(model)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val)\n",
    "        # Predict the test set\n",
    "        test_predictions += model.predict(x_test) / 10\n",
    "        \n",
    "    rmspe_score = rmspe(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    # Return test predictions\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-stone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.000473181\ttraining's RMSPE: 0.219006\tvalid_1's rmse: 0.000486846\tvalid_1's RMSPE: 0.225212\n",
      "[200]\ttraining's rmse: 0.000457561\ttraining's RMSPE: 0.211776\tvalid_1's rmse: 0.000475783\tvalid_1's RMSPE: 0.220095\n",
      "[300]\ttraining's rmse: 0.000446237\ttraining's RMSPE: 0.206535\tvalid_1's rmse: 0.000467194\tvalid_1's RMSPE: 0.216122\n",
      "[400]\ttraining's rmse: 0.000437508\ttraining's RMSPE: 0.202495\tvalid_1's rmse: 0.000460669\tvalid_1's RMSPE: 0.213103\n",
      "[500]\ttraining's rmse: 0.00043029\ttraining's RMSPE: 0.199154\tvalid_1's rmse: 0.000456661\tvalid_1's RMSPE: 0.211249\n",
      "[600]\ttraining's rmse: 0.000423433\ttraining's RMSPE: 0.19598\tvalid_1's rmse: 0.0004523\tvalid_1's RMSPE: 0.209232\n",
      "[700]\ttraining's rmse: 0.000417333\ttraining's RMSPE: 0.193157\tvalid_1's rmse: 0.000447933\tvalid_1's RMSPE: 0.207212\n",
      "[800]\ttraining's rmse: 0.00041227\ttraining's RMSPE: 0.190814\tvalid_1's rmse: 0.000445541\tvalid_1's RMSPE: 0.206105\n",
      "[900]\ttraining's rmse: 0.000408296\ttraining's RMSPE: 0.188974\tvalid_1's rmse: 0.000443511\tvalid_1's RMSPE: 0.205166\n"
     ]
    }
   ],
   "source": [
    "models = train_models(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wooden-credits",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<lightgbm.basic.Booster at 0x7f23b37ed340>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "central-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = train_df.drop(['row_id', 'time_id', 'target'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dying-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = models[0].predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "inclusive-argument",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428932,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "trained-scottish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428932,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "exposed-spyware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2525921853990848"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(preds, train_df.target.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-fabric",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python38564bitfastaicondad52d12c5a30a4725bf9d3e235cf1271c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
