{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641b8a4f",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- tendency features\n",
    "\n",
    "- subtract windows\n",
    "\n",
    "- skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef66a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df = pd.read_parquet(self.data_dir / f'trade_train.parquet/stock_id=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a21aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f178cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from optuna.integration import FastAIPruningCallback\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac44d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOCK_COUNT = 112\n",
    "FEATURE_COUNT = 144#20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee3a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(train_df):\n",
    "    all_times = train_df.time_id.unique()\n",
    "    all_stocks = train_df.stock_id.unique()\n",
    "    filled_df = train_df.copy()\n",
    "    filled_df=filled_df.set_index(['time_id', 'stock_id'])\n",
    "    new_index = pd.MultiIndex.from_product([all_times, all_stocks], names = ['time_id', 'stock_id'])\n",
    "    filled_df = filled_df.reindex(new_index).reset_index()\n",
    "    filled_df = filled_df.fillna(0)\n",
    "    return filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3efd558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_trade_count(train_df):\n",
    "    for s,e in time_windows:\n",
    "        train_df[f'number_trades_{s}_{e}'] = 'more'\n",
    "        for val in range(3): train_df.loc[train_df[f'seconds_in_bucket_size_{s}_{e}']==val, f'number_trades_{s}_{e}'] = val\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dfa80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Jitter(ItemTransform):\n",
    "    def __init__(self, jit_std):\n",
    "            super().__init__()\n",
    "            self.split_idx = 0\n",
    "            self.jit_std = jit_std\n",
    "            \n",
    "    def encodes(self, b):\n",
    "        #print('doing jitter ', self.jit_std)\n",
    "        jitter = torch.empty_like(b[1]).normal_(0, self.jit_std)\n",
    "        b[1] += jitter\n",
    "        return b\n",
    "\n",
    "class MaskTfm(ItemTransform):\n",
    "    \n",
    "    def __init__(self, mask_perc):\n",
    "        super().__init__()\n",
    "        self.split_idx = 0\n",
    "        self.mask_perc = mask_perc\n",
    "    \n",
    "    def mask(self, x, indices):\n",
    "        x[torch.tensor(indices, device=x.device)] = 0\n",
    "        return x\n",
    "    \n",
    "    def encodes(self, x):\n",
    "        #print('doing mask', self.mask_perc)\n",
    "        n = len(x[0])\n",
    "        to_mask = (n * self.mask_perc) // 100\n",
    "        indices = np.random.choice(np.array(range(n)), to_mask, replace=False)\n",
    "        x = [self.mask(y, indices) for y in x]\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MyDataLoader(TabDataLoader):\n",
    "    def __init__(self, dataset, jit_std, mask_perc, bs=16, shuffle=False, after_batch=None, num_workers=0,  **kwargs):\n",
    "        if after_batch is None: after_batch = L(TransformBlock().batch_tfms)+ReadTabBatch(dataset) + [Jitter(jit_std), MaskTfm(mask_perc)]\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)\n",
    "\n",
    "    def shuffle_fn(self, idxs):\n",
    "        idxs = np.array(idxs).reshape(-1,112)\n",
    "        np.random.shuffle(idxs)\n",
    "        return idxs.reshape(-1).tolist()\n",
    "\n",
    "def get_dls(train_df, bs, trn_idx, val_idx, jit_std=.13, mask_perc=8):\n",
    "    cont_nn,cat_nn = cont_cat_split(train_df, max_card=9000, dep_var='target')\n",
    "    cat_nn=[x for x in cat_nn if not x in ['row_id', 'time_id']]\n",
    "    \n",
    "    procs_nn = [Categorify, Normalize]\n",
    "    to_nn = TabularPandas(train_df, procs_nn, cat_nn, cont_nn, splits=[list(trn_idx), list(val_idx)], y_names='target')\n",
    "    dls = to_nn.dataloaders(bs=112*100, shuffle=True, dl_type = MyDataLoader, jit_std=jit_std, mask_perc=mask_perc)\n",
    "    dls.train_ds.split_idx=0\n",
    "    dls.valid_ds.split_idx=1\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e5d448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "306c70ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = pd.read_feather('train_24cols.feather')\n",
    "# train_df = pd.read_feather('train_126ftrs.feater')\n",
    "# train_df = fill_missing(train_df)\n",
    "# train_df = append_trade_count(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "393ff6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEncoding(nn.Module):\n",
    "    def __init__(self, inp_size, bottleneck, p, multiplier):\n",
    "        super().__init__()\n",
    "        self.multiplier  = multiplier#nn.Parameter(torch.tensor(multiplier)) \n",
    "        self.initial_layers = LinBnDrop(inp_size, bottleneck, act=nn.ReLU(True), p=p, bn=False)\n",
    "        \n",
    "        self.concat_layers = nn.Sequential(\n",
    "            nn.BatchNorm1d(bottleneck * STOCK_COUNT),\n",
    "            nn.Linear(bottleneck * STOCK_COUNT, inp_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.initial_layers(x)\n",
    "        times = y.shape[0] // STOCK_COUNT\n",
    "        y = y.view(times, -1)\n",
    "        y = self.concat_layers(y)\n",
    "   \n",
    "        y = y.view(times,1,-1).expand(times,STOCK_COUNT,-1).contiguous().view(times*STOCK_COUNT, -1)\n",
    "        \n",
    "        return x + y * self.multiplier\n",
    "\n",
    "class BN(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super().__init__()\n",
    "        self.num_features = features\n",
    "        self.bn = nn.BatchNorm1d(STOCK_COUNT * self.num_features)\n",
    "    def forward(self, x):\n",
    "        sh = x.shape\n",
    "        x = x.view(-1, STOCK_COUNT * self.num_features)\n",
    "        x = self.bn(x)\n",
    "        return x.view(*sh)\n",
    "    \n",
    "class ParallelModel(nn.Module):\n",
    "    def __init__(self, inp_size, emb_szs, lin_sizes, ps, bottleneck, time_ps, multipliers, embed_p ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.embed_drop = nn.Dropout(embed_p)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        \n",
    "        lin_sizes = [inp_size+n_emb] + lin_sizes\n",
    "        layers = []\n",
    "        for n_in, n_out, p, time_p, multiplier in zip(lin_sizes, lin_sizes[1:], ps, time_ps, multipliers):\n",
    "            layers.append(nn.Linear(n_in, n_out))\n",
    "            layers.append(BN(n_out ))\n",
    "            if p: layers.append(nn.Dropout(p))\n",
    "            \n",
    "            layers.append(nn.ReLU(True))\n",
    "            \n",
    "            layers.append(TimeEncoding(n_out, bottleneck, time_p, multiplier))\n",
    "        layers.append(LinBnDrop(lin_sizes[-1], 1, bn=False))\n",
    "        layers.append(SigmoidRange(0, .1))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.embed_drop(x)\n",
    "        x = torch.cat([x_cont, x], dim=1)\n",
    "        for l in self.layers.children():\n",
    "            #print(x.shape, x.mean(), x.std())\n",
    "            x = l(x)\n",
    "        return x#self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4effc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(preds, targs):\n",
    "    mask = targs != 0\n",
    "    targs, preds = torch.masked_select(targs, mask), torch.masked_select(preds, mask)\n",
    "    x = (targs-preds)/targs\n",
    "    res= (x**2).mean().sqrt()\n",
    "    if torch.isnan(res): \n",
    "        print(targs)\n",
    "        print(preds)\n",
    "        raise Exception('fck loss is nan')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39d0eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trial, train_df, trn_idx, val_idx, save_as=None):\n",
    "   \n",
    "    jit_std=trial.suggest_float('jit_std', 0, .5)\n",
    "    mask_perc=trial.suggest_int('mask_perc', 0, 20)\n",
    "    \n",
    "    dls = get_dls(train_df, 100, trn_idx, val_idx, jit_std=jit_std, mask_perc = mask_perc)\n",
    "    inp_size = len(dls.cont_names)\n",
    "    emb_size = trial.suggest_int('emb_size', 3, 30)\n",
    "    emb_sizes = [(len(c_vals), emb_size if c_name == 'stock_id' else 3) for c_name, c_vals in dls.train.classes.items()]\n",
    "    emb_p = trial.suggest_float(f'emb_p', 0, .5)\n",
    "    max_sizes = [2000, 1000, 500]\n",
    "    lin_sizes = [500,500,500]#[trial.suggest_int(f'lin_size{i}', 10, ms) for i, ms in enumerate(max_sizes)]\n",
    "    ps = [0]+[trial.suggest_float(f'p{i}', 0, .8) for i in range(1,3)]\n",
    "    \n",
    "    bottleneck = trial.suggest_int('bottleneck', 5, 100)\n",
    "    time_ps = [trial.suggest_float(f'time_p{i}', 0, .5) for i in range(3)]\n",
    "    multipliers = [trial.suggest_float(f'multiplier{i}', .01, .5) for i in range(3)]\n",
    "    lr = float(trial.suggest_float('lr', 1e-3, 1e-2))\n",
    "\n",
    "    \n",
    "    \n",
    "    model = ParallelModel(inp_size, emb_sizes, lin_sizes, ps, bottleneck, time_ps, multipliers, emb_p)\n",
    "    learn = Learner(dls,model = model, loss_func=rmspe, metrics=AccumMetric(rmspe), opt_func=ranger,\n",
    "        cbs = FastAIPruningCallback(trial, 'rmspe')).to_fp16()\n",
    "    # with learn.no_bar():\n",
    "    #     with learn.no_logging():    \n",
    "    learn.fit_flat_cos(70, lr)\n",
    "    if save_as:\n",
    "        learn.save(save_as)\n",
    "    last5 = L(learn.recorder.values).itemgot(2)[-5:]\n",
    "    return np.mean(last5)\n",
    "\n",
    "def train_cross_valid(trial, train_df, save_as=None):\n",
    "    res = 0\n",
    "    splits = GroupKFold().split(train_df, groups = train_df.time_id)\n",
    "    for idx, (trn_idx, val_idx) in enumerate(splits):\n",
    "        v = train(trial, train_df, trn_idx, val_idx, save_as + str(idx) if save_as else None)\n",
    "        print(f'fold {idx}: {v}')\n",
    "        res +=v;\n",
    "    return res/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4c612",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd96c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optiver_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f305a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_feature_dict = {\n",
    "#     wap1: [np.mean, np.std, 'nunique'],\n",
    "#     wap2: [np.mean, np.std],\n",
    "#     log_return1: [np.std],\n",
    "#     log_return2: [np.std],\n",
    "#     ask_spread: [np.mean, np.std],\n",
    "#     price_spread:[np.mean, np.std],\n",
    "#     total_volume:[np.mean, np.std],\n",
    "# }\n",
    "# trade_feature_dict = {\n",
    "#         log_return_price: [np.std, np.mean],\n",
    "#         'seconds_in_bucket':[np.size],\n",
    "#         'size':[np.sum],\n",
    "#         'order_count':[np.sum],\n",
    "# }\n",
    "\n",
    "time_windows = [(0,600), (0,100), (100,200), (200,300), (300,400), (400, 500), (500,600)]\n",
    "# ofg = OptiverFeatureGenerator(book_feature_dict, trade_feature_dict, time_windows)\n",
    "# #train_gen = ofg.generate_train_df()\n",
    "\n",
    "\n",
    "# train_gen.to_feather('train_126ftrs.feater')\n",
    "\n",
    "# train_gen = fill_missing(train_gen)\n",
    "\n",
    "# FEATURE_COUNT = len(train_gen.columns) - 4\n",
    "\n",
    "# FEATURE_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71b04009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tauify(train_df):\n",
    "    for c in train_df.columns:\n",
    "        if 'sum' in c: train_df[c] = np.sqrt(1/(train_df[c]+1))\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d57de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_feather('train_126ftrs.feater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1d57c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = fill_missing(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e804558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = append_trade_count(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27a90618",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tauify(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9de60",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bc37225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-22 16:46:50,411]\u001b[0m Using an existing study with name 'train_126ftrs' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", study_name = 'train_126ftrs', storage='sqlite:///optuna.db', load_if_exists=True, pruner=optuna.pruners.NopPruner(), sampler=None)\n",
    "#study.optimize(functools.partial(train, train_df=train_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7aef050",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a3f1472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bottleneck': 46,\n",
       " 'emb_p': 0.3454992150001027,\n",
       " 'emb_size': 4,\n",
       " 'jit_std': 0.03325574203203305,\n",
       " 'lr': 0.008414558376176162,\n",
       " 'mask_perc': 11,\n",
       " 'multiplier0': 0.18052589333779923,\n",
       " 'multiplier1': 0.29552707702438435,\n",
       " 'multiplier2': 0.040720708464957234,\n",
       " 'p1': 0.5240166648872739,\n",
       " 'p2': 0.2709588165106582,\n",
       " 'time_p0': 0.26394511771559187,\n",
       " 'time_p1': 0.2605308389420442,\n",
       " 'time_p2': 0.11181420784350192}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15de2c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_params = {\n",
    " 'bottleneck': 50,\n",
    " 'emb_p': 0.3,\n",
    " 'emb_size': 10,\n",
    " 'jit_std': 0.03,\n",
    " 'lr': 0.008,\n",
    " 'mask_perc': 10,\n",
    " 'multiplier0': 0.2,\n",
    " 'multiplier1': 0.3,\n",
    " 'multiplier2': 0.05,\n",
    " 'p1': 0.5,\n",
    " 'p2': 0.25,\n",
    " 'time_p0': 0.25,\n",
    " 'time_p1': 0.25,\n",
    " 'time_p2': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99f1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2675522/400058951.py:1: ExperimentalWarning: create_trial is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "  my_trial = optuna.create_trial(value=42, params=my_params, distributions=best.distributions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(113, 10)\n",
      "    (1): Embedding(5, 3)\n",
      "    (2): Embedding(5, 3)\n",
      "    (3): Embedding(5, 3)\n",
      "    (4): Embedding(5, 3)\n",
      "    (5): Embedding(5, 3)\n",
      "    (6): Embedding(5, 3)\n",
      "    (7): Embedding(5, 3)\n",
      "  )\n",
      "  (embed_drop): Dropout(p=0.3, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=157, out_features=500, bias=True)\n",
      "    (1): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.25, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (5): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.25, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (9): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (10): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): Dropout(p=0.25, inplace=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (14): LinBnDrop(\n",
      "      (0): Linear(in_features=500, out_features=1, bias=True)\n",
      "    )\n",
      "    (15): SigmoidRange(low=0, high=0.1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.305089</td>\n",
       "      <td>1.091941</td>\n",
       "      <td>1.092139</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.532663</td>\n",
       "      <td>0.548270</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.994931</td>\n",
       "      <td>0.472842</td>\n",
       "      <td>0.473089</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.751250</td>\n",
       "      <td>0.569851</td>\n",
       "      <td>0.570385</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.614002</td>\n",
       "      <td>0.357552</td>\n",
       "      <td>0.358195</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.523175</td>\n",
       "      <td>0.353368</td>\n",
       "      <td>0.353703</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.514699</td>\n",
       "      <td>0.483642</td>\n",
       "      <td>0.483809</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.460463</td>\n",
       "      <td>0.307705</td>\n",
       "      <td>0.307839</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.424120</td>\n",
       "      <td>0.248571</td>\n",
       "      <td>0.248682</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.382965</td>\n",
       "      <td>0.249547</td>\n",
       "      <td>0.249601</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.352953</td>\n",
       "      <td>0.231560</td>\n",
       "      <td>0.231693</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.336947</td>\n",
       "      <td>0.223217</td>\n",
       "      <td>0.223243</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.320747</td>\n",
       "      <td>0.253507</td>\n",
       "      <td>0.253734</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.309798</td>\n",
       "      <td>0.237143</td>\n",
       "      <td>0.237180</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.296990</td>\n",
       "      <td>0.266318</td>\n",
       "      <td>0.266334</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.300286</td>\n",
       "      <td>0.237932</td>\n",
       "      <td>0.238039</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.299567</td>\n",
       "      <td>0.259176</td>\n",
       "      <td>0.259256</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.297982</td>\n",
       "      <td>0.262730</td>\n",
       "      <td>0.262933</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.288798</td>\n",
       "      <td>0.261126</td>\n",
       "      <td>0.261268</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.285128</td>\n",
       "      <td>0.218470</td>\n",
       "      <td>0.218541</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.279038</td>\n",
       "      <td>0.218068</td>\n",
       "      <td>0.218142</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.275003</td>\n",
       "      <td>0.233920</td>\n",
       "      <td>0.233969</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.272639</td>\n",
       "      <td>0.238447</td>\n",
       "      <td>0.238481</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.261174</td>\n",
       "      <td>0.261284</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.285496</td>\n",
       "      <td>0.239363</td>\n",
       "      <td>0.239433</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.285035</td>\n",
       "      <td>0.234327</td>\n",
       "      <td>0.234341</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.277811</td>\n",
       "      <td>0.218123</td>\n",
       "      <td>0.218180</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.273936</td>\n",
       "      <td>0.252276</td>\n",
       "      <td>0.252370</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.277263</td>\n",
       "      <td>0.227721</td>\n",
       "      <td>0.227893</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.272817</td>\n",
       "      <td>0.222865</td>\n",
       "      <td>0.222916</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.266078</td>\n",
       "      <td>0.223162</td>\n",
       "      <td>0.223192</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.266837</td>\n",
       "      <td>0.221475</td>\n",
       "      <td>0.221695</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.258171</td>\n",
       "      <td>0.217845</td>\n",
       "      <td>0.217964</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.256613</td>\n",
       "      <td>0.218280</td>\n",
       "      <td>0.218357</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.257347</td>\n",
       "      <td>0.255903</td>\n",
       "      <td>0.255967</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.258479</td>\n",
       "      <td>0.232684</td>\n",
       "      <td>0.232808</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.255230</td>\n",
       "      <td>0.221227</td>\n",
       "      <td>0.221391</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.252105</td>\n",
       "      <td>0.222869</td>\n",
       "      <td>0.222965</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.252585</td>\n",
       "      <td>0.224910</td>\n",
       "      <td>0.224942</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.253218</td>\n",
       "      <td>0.231684</td>\n",
       "      <td>0.231793</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.254219</td>\n",
       "      <td>0.233910</td>\n",
       "      <td>0.233923</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.252251</td>\n",
       "      <td>0.234553</td>\n",
       "      <td>0.234667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.252276</td>\n",
       "      <td>0.217572</td>\n",
       "      <td>0.217638</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.248463</td>\n",
       "      <td>0.220756</td>\n",
       "      <td>0.220825</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.247651</td>\n",
       "      <td>0.214712</td>\n",
       "      <td>0.214785</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.249025</td>\n",
       "      <td>0.247254</td>\n",
       "      <td>0.247375</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.252228</td>\n",
       "      <td>0.214314</td>\n",
       "      <td>0.214360</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.245302</td>\n",
       "      <td>0.214885</td>\n",
       "      <td>0.214951</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.241746</td>\n",
       "      <td>0.224468</td>\n",
       "      <td>0.224534</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.242631</td>\n",
       "      <td>0.226185</td>\n",
       "      <td>0.226331</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.244506</td>\n",
       "      <td>0.221031</td>\n",
       "      <td>0.221121</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.245380</td>\n",
       "      <td>0.222341</td>\n",
       "      <td>0.222372</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.242906</td>\n",
       "      <td>0.213616</td>\n",
       "      <td>0.213666</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.237188</td>\n",
       "      <td>0.224209</td>\n",
       "      <td>0.224335</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.234984</td>\n",
       "      <td>0.224411</td>\n",
       "      <td>0.224526</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.234026</td>\n",
       "      <td>0.242908</td>\n",
       "      <td>0.242973</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.233283</td>\n",
       "      <td>0.216257</td>\n",
       "      <td>0.216401</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.232684</td>\n",
       "      <td>0.232704</td>\n",
       "      <td>0.232851</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.234012</td>\n",
       "      <td>0.233365</td>\n",
       "      <td>0.233480</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.229462</td>\n",
       "      <td>0.214594</td>\n",
       "      <td>0.214667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.226762</td>\n",
       "      <td>0.218157</td>\n",
       "      <td>0.218364</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.223293</td>\n",
       "      <td>0.216587</td>\n",
       "      <td>0.216673</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.220325</td>\n",
       "      <td>0.214437</td>\n",
       "      <td>0.214542</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.221432</td>\n",
       "      <td>0.223076</td>\n",
       "      <td>0.223236</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.217684</td>\n",
       "      <td>0.214878</td>\n",
       "      <td>0.214993</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.214541</td>\n",
       "      <td>0.215799</td>\n",
       "      <td>0.216021</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.212698</td>\n",
       "      <td>0.218189</td>\n",
       "      <td>0.218494</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.210722</td>\n",
       "      <td>0.216084</td>\n",
       "      <td>0.216263</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.210033</td>\n",
       "      <td>0.217015</td>\n",
       "      <td>0.217242</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.209616</td>\n",
       "      <td>0.218144</td>\n",
       "      <td>0.218364</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: 0.21727699935436248\n",
      "ParallelModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(113, 10)\n",
      "    (1): Embedding(5, 3)\n",
      "    (2): Embedding(5, 3)\n",
      "    (3): Embedding(5, 3)\n",
      "    (4): Embedding(5, 3)\n",
      "    (5): Embedding(5, 3)\n",
      "    (6): Embedding(5, 3)\n",
      "    (7): Embedding(5, 3)\n",
      "  )\n",
      "  (embed_drop): Dropout(p=0.3, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=157, out_features=500, bias=True)\n",
      "    (1): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.25, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (5): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.25, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (9): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (10): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): Dropout(p=0.25, inplace=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (14): LinBnDrop(\n",
      "      (0): Linear(in_features=500, out_features=1, bias=True)\n",
      "    )\n",
      "    (15): SigmoidRange(low=0, high=0.1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.816119</td>\n",
       "      <td>2.875728</td>\n",
       "      <td>2.882589</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.722816</td>\n",
       "      <td>0.703676</td>\n",
       "      <td>0.704795</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.108319</td>\n",
       "      <td>1.010759</td>\n",
       "      <td>1.012040</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.828232</td>\n",
       "      <td>0.439121</td>\n",
       "      <td>0.439715</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.668083</td>\n",
       "      <td>0.378399</td>\n",
       "      <td>0.379339</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.346975</td>\n",
       "      <td>0.347476</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.519460</td>\n",
       "      <td>0.386740</td>\n",
       "      <td>0.387331</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.470901</td>\n",
       "      <td>0.287267</td>\n",
       "      <td>0.287619</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.426239</td>\n",
       "      <td>0.283574</td>\n",
       "      <td>0.283656</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.383202</td>\n",
       "      <td>0.241213</td>\n",
       "      <td>0.241328</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.353115</td>\n",
       "      <td>0.264379</td>\n",
       "      <td>0.264503</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.338938</td>\n",
       "      <td>0.265636</td>\n",
       "      <td>0.265667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.328095</td>\n",
       "      <td>0.276431</td>\n",
       "      <td>0.276484</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.318543</td>\n",
       "      <td>0.247304</td>\n",
       "      <td>0.247628</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.312592</td>\n",
       "      <td>0.244372</td>\n",
       "      <td>0.244506</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.301185</td>\n",
       "      <td>0.239745</td>\n",
       "      <td>0.239807</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.299593</td>\n",
       "      <td>0.242147</td>\n",
       "      <td>0.242351</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.290652</td>\n",
       "      <td>0.232038</td>\n",
       "      <td>0.232163</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.288208</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.282909</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.285594</td>\n",
       "      <td>0.299393</td>\n",
       "      <td>0.299516</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.284685</td>\n",
       "      <td>0.242184</td>\n",
       "      <td>0.242256</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.283613</td>\n",
       "      <td>0.267738</td>\n",
       "      <td>0.267796</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.285991</td>\n",
       "      <td>0.237404</td>\n",
       "      <td>0.237512</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.290812</td>\n",
       "      <td>0.245820</td>\n",
       "      <td>0.245855</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.287865</td>\n",
       "      <td>0.276965</td>\n",
       "      <td>0.277125</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.283269</td>\n",
       "      <td>0.227107</td>\n",
       "      <td>0.227175</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.282165</td>\n",
       "      <td>0.242521</td>\n",
       "      <td>0.242628</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.278125</td>\n",
       "      <td>0.294451</td>\n",
       "      <td>0.294511</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.274463</td>\n",
       "      <td>0.252515</td>\n",
       "      <td>0.252936</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.276872</td>\n",
       "      <td>0.227527</td>\n",
       "      <td>0.227620</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.269546</td>\n",
       "      <td>0.234169</td>\n",
       "      <td>0.234422</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.264854</td>\n",
       "      <td>0.227361</td>\n",
       "      <td>0.227569</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.273899</td>\n",
       "      <td>0.263991</td>\n",
       "      <td>0.264046</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.269721</td>\n",
       "      <td>0.224310</td>\n",
       "      <td>0.224397</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.262611</td>\n",
       "      <td>0.248580</td>\n",
       "      <td>0.249103</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.264278</td>\n",
       "      <td>0.282363</td>\n",
       "      <td>0.282386</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.262952</td>\n",
       "      <td>0.218044</td>\n",
       "      <td>0.218108</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.260592</td>\n",
       "      <td>0.280633</td>\n",
       "      <td>0.280701</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.265553</td>\n",
       "      <td>0.238364</td>\n",
       "      <td>0.238435</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.261373</td>\n",
       "      <td>0.243746</td>\n",
       "      <td>0.244096</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.258629</td>\n",
       "      <td>0.250271</td>\n",
       "      <td>0.250341</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.254020</td>\n",
       "      <td>0.232029</td>\n",
       "      <td>0.232239</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.252893</td>\n",
       "      <td>0.262971</td>\n",
       "      <td>0.263185</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.252755</td>\n",
       "      <td>0.232569</td>\n",
       "      <td>0.232737</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.250412</td>\n",
       "      <td>0.221754</td>\n",
       "      <td>0.221880</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.245269</td>\n",
       "      <td>0.232863</td>\n",
       "      <td>0.233037</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.242246</td>\n",
       "      <td>0.216447</td>\n",
       "      <td>0.216516</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.247854</td>\n",
       "      <td>0.226814</td>\n",
       "      <td>0.227015</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.245945</td>\n",
       "      <td>0.222755</td>\n",
       "      <td>0.222826</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.246161</td>\n",
       "      <td>0.235411</td>\n",
       "      <td>0.235547</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.244827</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.224952</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.220240</td>\n",
       "      <td>0.220319</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.244889</td>\n",
       "      <td>0.229411</td>\n",
       "      <td>0.229480</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.241479</td>\n",
       "      <td>0.220871</td>\n",
       "      <td>0.221088</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.241337</td>\n",
       "      <td>0.261291</td>\n",
       "      <td>0.261344</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.240855</td>\n",
       "      <td>0.227158</td>\n",
       "      <td>0.227248</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.236526</td>\n",
       "      <td>0.226638</td>\n",
       "      <td>0.226845</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.234152</td>\n",
       "      <td>0.227488</td>\n",
       "      <td>0.227627</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.233670</td>\n",
       "      <td>0.230824</td>\n",
       "      <td>0.231056</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.232301</td>\n",
       "      <td>0.218407</td>\n",
       "      <td>0.218556</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.227516</td>\n",
       "      <td>0.219266</td>\n",
       "      <td>0.219472</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.220158</td>\n",
       "      <td>0.220357</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.225935</td>\n",
       "      <td>0.217993</td>\n",
       "      <td>0.218161</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.221669</td>\n",
       "      <td>0.220419</td>\n",
       "      <td>0.220591</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.218872</td>\n",
       "      <td>0.221597</td>\n",
       "      <td>0.221903</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.219934</td>\n",
       "      <td>0.220141</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.215668</td>\n",
       "      <td>0.221300</td>\n",
       "      <td>0.221526</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.214734</td>\n",
       "      <td>0.219669</td>\n",
       "      <td>0.219854</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.213440</td>\n",
       "      <td>0.222455</td>\n",
       "      <td>0.222708</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.212959</td>\n",
       "      <td>0.220281</td>\n",
       "      <td>0.220482</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1: 0.2209423452615738\n",
      "ParallelModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(113, 10)\n",
      "    (1): Embedding(5, 3)\n",
      "    (2): Embedding(5, 3)\n",
      "    (3): Embedding(5, 3)\n",
      "    (4): Embedding(5, 3)\n",
      "    (5): Embedding(5, 3)\n",
      "    (6): Embedding(5, 3)\n",
      "    (7): Embedding(5, 3)\n",
      "  )\n",
      "  (embed_drop): Dropout(p=0.3, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=157, out_features=500, bias=True)\n",
      "    (1): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.25, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (5): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.25, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (9): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (10): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): Dropout(p=0.25, inplace=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (14): LinBnDrop(\n",
      "      (0): Linear(in_features=500, out_features=1, bias=True)\n",
      "    )\n",
      "    (15): SigmoidRange(low=0, high=0.1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.628363</td>\n",
       "      <td>2.417254</td>\n",
       "      <td>2.422177</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.682474</td>\n",
       "      <td>0.751774</td>\n",
       "      <td>0.752973</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.056371</td>\n",
       "      <td>0.522094</td>\n",
       "      <td>0.522958</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.783345</td>\n",
       "      <td>0.610790</td>\n",
       "      <td>0.612147</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.638882</td>\n",
       "      <td>0.384919</td>\n",
       "      <td>0.386427</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.543611</td>\n",
       "      <td>0.340675</td>\n",
       "      <td>0.341832</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.493437</td>\n",
       "      <td>0.275534</td>\n",
       "      <td>0.275970</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.424491</td>\n",
       "      <td>0.246230</td>\n",
       "      <td>0.247415</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.380143</td>\n",
       "      <td>0.262474</td>\n",
       "      <td>0.262909</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.360392</td>\n",
       "      <td>0.274952</td>\n",
       "      <td>0.275686</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.340454</td>\n",
       "      <td>0.254888</td>\n",
       "      <td>0.255790</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.326212</td>\n",
       "      <td>0.255586</td>\n",
       "      <td>0.255911</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.316760</td>\n",
       "      <td>0.276374</td>\n",
       "      <td>0.276554</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.309689</td>\n",
       "      <td>0.230589</td>\n",
       "      <td>0.230930</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.303045</td>\n",
       "      <td>0.230474</td>\n",
       "      <td>0.230934</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.302362</td>\n",
       "      <td>0.230612</td>\n",
       "      <td>0.231165</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.293462</td>\n",
       "      <td>0.222371</td>\n",
       "      <td>0.222612</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.288696</td>\n",
       "      <td>0.220733</td>\n",
       "      <td>0.221220</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.284730</td>\n",
       "      <td>0.254296</td>\n",
       "      <td>0.255034</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.282314</td>\n",
       "      <td>0.221374</td>\n",
       "      <td>0.221945</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.280329</td>\n",
       "      <td>0.271316</td>\n",
       "      <td>0.272070</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.279301</td>\n",
       "      <td>0.228010</td>\n",
       "      <td>0.228403</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.273611</td>\n",
       "      <td>0.222072</td>\n",
       "      <td>0.222566</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.224556</td>\n",
       "      <td>0.225685</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.268584</td>\n",
       "      <td>0.222474</td>\n",
       "      <td>0.223211</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.276879</td>\n",
       "      <td>0.256715</td>\n",
       "      <td>0.257086</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.271495</td>\n",
       "      <td>0.226223</td>\n",
       "      <td>0.226625</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.269131</td>\n",
       "      <td>0.233637</td>\n",
       "      <td>0.233812</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.268494</td>\n",
       "      <td>0.218280</td>\n",
       "      <td>0.218773</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.266647</td>\n",
       "      <td>0.224634</td>\n",
       "      <td>0.225170</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.262909</td>\n",
       "      <td>0.243447</td>\n",
       "      <td>0.243658</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.259605</td>\n",
       "      <td>0.220815</td>\n",
       "      <td>0.222386</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.256893</td>\n",
       "      <td>0.241606</td>\n",
       "      <td>0.241953</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.254791</td>\n",
       "      <td>0.242534</td>\n",
       "      <td>0.242823</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.250029</td>\n",
       "      <td>0.220002</td>\n",
       "      <td>0.220659</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.251338</td>\n",
       "      <td>0.221373</td>\n",
       "      <td>0.222016</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.244090</td>\n",
       "      <td>0.217712</td>\n",
       "      <td>0.218308</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.246894</td>\n",
       "      <td>0.225742</td>\n",
       "      <td>0.225948</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.239468</td>\n",
       "      <td>0.223448</td>\n",
       "      <td>0.224005</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.236564</td>\n",
       "      <td>0.222728</td>\n",
       "      <td>0.223193</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.233597</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>0.244902</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.232518</td>\n",
       "      <td>0.215880</td>\n",
       "      <td>0.216274</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.230929</td>\n",
       "      <td>0.215607</td>\n",
       "      <td>0.215889</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.229249</td>\n",
       "      <td>0.215914</td>\n",
       "      <td>0.216290</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.221573</td>\n",
       "      <td>0.222138</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.232812</td>\n",
       "      <td>0.228382</td>\n",
       "      <td>0.228921</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.232646</td>\n",
       "      <td>0.240317</td>\n",
       "      <td>0.240725</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.228356</td>\n",
       "      <td>0.229949</td>\n",
       "      <td>0.230579</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>0.231340</td>\n",
       "      <td>0.232667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.226248</td>\n",
       "      <td>0.218483</td>\n",
       "      <td>0.219270</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.227459</td>\n",
       "      <td>0.218252</td>\n",
       "      <td>0.218874</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.227243</td>\n",
       "      <td>0.225235</td>\n",
       "      <td>0.225943</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.223234</td>\n",
       "      <td>0.227006</td>\n",
       "      <td>0.227784</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.222769</td>\n",
       "      <td>0.248450</td>\n",
       "      <td>0.249823</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.226141</td>\n",
       "      <td>0.246726</td>\n",
       "      <td>0.247386</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.221813</td>\n",
       "      <td>0.224465</td>\n",
       "      <td>0.225068</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.218577</td>\n",
       "      <td>0.218317</td>\n",
       "      <td>0.219092</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.217917</td>\n",
       "      <td>0.220077</td>\n",
       "      <td>0.221286</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.217846</td>\n",
       "      <td>0.227831</td>\n",
       "      <td>0.228400</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.213219</td>\n",
       "      <td>0.222594</td>\n",
       "      <td>0.223113</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.212647</td>\n",
       "      <td>0.218855</td>\n",
       "      <td>0.219470</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.210438</td>\n",
       "      <td>0.219186</td>\n",
       "      <td>0.219954</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.207766</td>\n",
       "      <td>0.218515</td>\n",
       "      <td>0.219258</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.206496</td>\n",
       "      <td>0.220239</td>\n",
       "      <td>0.220972</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.204519</td>\n",
       "      <td>0.217892</td>\n",
       "      <td>0.218579</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.202945</td>\n",
       "      <td>0.220404</td>\n",
       "      <td>0.221204</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.202252</td>\n",
       "      <td>0.219013</td>\n",
       "      <td>0.219783</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.201417</td>\n",
       "      <td>0.219264</td>\n",
       "      <td>0.220059</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.200167</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.218846</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.199968</td>\n",
       "      <td>0.219624</td>\n",
       "      <td>0.220405</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2: 0.22005947530269623\n",
      "ParallelModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(113, 10)\n",
      "    (1): Embedding(5, 3)\n",
      "    (2): Embedding(5, 3)\n",
      "    (3): Embedding(5, 3)\n",
      "    (4): Embedding(5, 3)\n",
      "    (5): Embedding(5, 3)\n",
      "    (6): Embedding(5, 3)\n",
      "    (7): Embedding(5, 3)\n",
      "  )\n",
      "  (embed_drop): Dropout(p=0.3, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=157, out_features=500, bias=True)\n",
      "    (1): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.25, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (5): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.25, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (9): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (10): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): Dropout(p=0.25, inplace=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (14): LinBnDrop(\n",
      "      (0): Linear(in_features=500, out_features=1, bias=True)\n",
      "    )\n",
      "    (15): SigmoidRange(low=0, high=0.1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.480993</td>\n",
       "      <td>1.498837</td>\n",
       "      <td>1.500915</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.653935</td>\n",
       "      <td>0.556064</td>\n",
       "      <td>0.556676</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.061419</td>\n",
       "      <td>0.532319</td>\n",
       "      <td>0.533117</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.781634</td>\n",
       "      <td>0.425451</td>\n",
       "      <td>0.426870</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.630530</td>\n",
       "      <td>0.382804</td>\n",
       "      <td>0.384410</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.560638</td>\n",
       "      <td>0.508355</td>\n",
       "      <td>0.508897</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.507298</td>\n",
       "      <td>0.385905</td>\n",
       "      <td>0.386741</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.460703</td>\n",
       "      <td>0.288887</td>\n",
       "      <td>0.289370</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.415734</td>\n",
       "      <td>0.252603</td>\n",
       "      <td>0.252681</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.376077</td>\n",
       "      <td>0.241618</td>\n",
       "      <td>0.241697</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.357833</td>\n",
       "      <td>0.238857</td>\n",
       "      <td>0.238959</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.336939</td>\n",
       "      <td>0.239278</td>\n",
       "      <td>0.239358</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.316877</td>\n",
       "      <td>0.225375</td>\n",
       "      <td>0.225441</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.306996</td>\n",
       "      <td>0.232645</td>\n",
       "      <td>0.232753</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.304626</td>\n",
       "      <td>0.280732</td>\n",
       "      <td>0.280809</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.299989</td>\n",
       "      <td>0.231110</td>\n",
       "      <td>0.231196</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.291023</td>\n",
       "      <td>0.237306</td>\n",
       "      <td>0.237403</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.286503</td>\n",
       "      <td>0.238695</td>\n",
       "      <td>0.238762</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.289185</td>\n",
       "      <td>0.239835</td>\n",
       "      <td>0.239924</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.282411</td>\n",
       "      <td>0.231724</td>\n",
       "      <td>0.231796</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.279394</td>\n",
       "      <td>0.282940</td>\n",
       "      <td>0.283127</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.277885</td>\n",
       "      <td>0.232199</td>\n",
       "      <td>0.232248</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.275791</td>\n",
       "      <td>0.240691</td>\n",
       "      <td>0.240743</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.272236</td>\n",
       "      <td>0.275751</td>\n",
       "      <td>0.275945</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.270708</td>\n",
       "      <td>0.228139</td>\n",
       "      <td>0.228233</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.264861</td>\n",
       "      <td>0.225523</td>\n",
       "      <td>0.225595</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.264525</td>\n",
       "      <td>0.238826</td>\n",
       "      <td>0.238860</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.262450</td>\n",
       "      <td>0.233658</td>\n",
       "      <td>0.233725</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.256311</td>\n",
       "      <td>0.226536</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.262963</td>\n",
       "      <td>0.235584</td>\n",
       "      <td>0.235661</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.257924</td>\n",
       "      <td>0.215973</td>\n",
       "      <td>0.216065</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.256892</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.216853</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.252577</td>\n",
       "      <td>0.220784</td>\n",
       "      <td>0.220888</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.247697</td>\n",
       "      <td>0.225991</td>\n",
       "      <td>0.226069</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.244136</td>\n",
       "      <td>0.226781</td>\n",
       "      <td>0.226835</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.248314</td>\n",
       "      <td>0.233092</td>\n",
       "      <td>0.233213</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.248416</td>\n",
       "      <td>0.231646</td>\n",
       "      <td>0.231685</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.247865</td>\n",
       "      <td>0.223735</td>\n",
       "      <td>0.223827</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.243253</td>\n",
       "      <td>0.220126</td>\n",
       "      <td>0.220263</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.242178</td>\n",
       "      <td>0.234749</td>\n",
       "      <td>0.234911</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.242004</td>\n",
       "      <td>0.216247</td>\n",
       "      <td>0.216319</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.236851</td>\n",
       "      <td>0.225167</td>\n",
       "      <td>0.225246</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.232746</td>\n",
       "      <td>0.222926</td>\n",
       "      <td>0.223046</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.232937</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.222470</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.240010</td>\n",
       "      <td>0.300187</td>\n",
       "      <td>0.307710</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.233896</td>\n",
       "      <td>0.261619</td>\n",
       "      <td>0.261665</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.232729</td>\n",
       "      <td>0.227877</td>\n",
       "      <td>0.227951</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.229293</td>\n",
       "      <td>0.222622</td>\n",
       "      <td>0.222760</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.226784</td>\n",
       "      <td>0.220331</td>\n",
       "      <td>0.220392</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.229358</td>\n",
       "      <td>0.225704</td>\n",
       "      <td>0.225752</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.226357</td>\n",
       "      <td>0.225071</td>\n",
       "      <td>0.225138</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.228822</td>\n",
       "      <td>0.223393</td>\n",
       "      <td>0.223507</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.226087</td>\n",
       "      <td>0.215344</td>\n",
       "      <td>0.215451</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.222104</td>\n",
       "      <td>0.223594</td>\n",
       "      <td>0.223867</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.225063</td>\n",
       "      <td>0.248596</td>\n",
       "      <td>0.248644</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.223255</td>\n",
       "      <td>0.217970</td>\n",
       "      <td>0.218074</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.219263</td>\n",
       "      <td>0.229417</td>\n",
       "      <td>0.230269</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.217867</td>\n",
       "      <td>0.231227</td>\n",
       "      <td>0.231838</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.215416</td>\n",
       "      <td>0.217908</td>\n",
       "      <td>0.218111</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.213143</td>\n",
       "      <td>0.248114</td>\n",
       "      <td>0.248219</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.214029</td>\n",
       "      <td>0.225478</td>\n",
       "      <td>0.225541</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.212720</td>\n",
       "      <td>0.216393</td>\n",
       "      <td>0.216465</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.209878</td>\n",
       "      <td>0.225704</td>\n",
       "      <td>0.225803</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.210021</td>\n",
       "      <td>0.216397</td>\n",
       "      <td>0.216501</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.209618</td>\n",
       "      <td>0.214255</td>\n",
       "      <td>0.214347</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.206258</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.214081</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.203875</td>\n",
       "      <td>0.214718</td>\n",
       "      <td>0.214798</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.202821</td>\n",
       "      <td>0.215616</td>\n",
       "      <td>0.215696</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.200860</td>\n",
       "      <td>0.216186</td>\n",
       "      <td>0.216275</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.199935</td>\n",
       "      <td>0.215709</td>\n",
       "      <td>0.215787</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3: 0.2153274655342102\n",
      "ParallelModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(113, 10)\n",
      "    (1): Embedding(5, 3)\n",
      "    (2): Embedding(5, 3)\n",
      "    (3): Embedding(5, 3)\n",
      "    (4): Embedding(5, 3)\n",
      "    (5): Embedding(5, 3)\n",
      "    (6): Embedding(5, 3)\n",
      "    (7): Embedding(5, 3)\n",
      "  )\n",
      "  (embed_drop): Dropout(p=0.3, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=157, out_features=500, bias=True)\n",
      "    (1): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.25, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (5): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.25, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (9): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (10): BN(\n",
      "      (bn): BatchNorm1d(56000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): Dropout(p=0.25, inplace=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): TimeEncoding(\n",
      "      (initial_layers): LinBnDrop(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Linear(in_features=500, out_features=50, bias=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (concat_layers): Sequential(\n",
      "        (0): BatchNorm1d(5600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): Linear(in_features=5600, out_features=500, bias=True)\n",
      "        (2): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (14): LinBnDrop(\n",
      "      (0): Linear(in_features=500, out_features=1, bias=True)\n",
      "    )\n",
      "    (15): SigmoidRange(low=0, high=0.1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='42' class='' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      60.00% [42/70 01:19<00:53]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.703702</td>\n",
       "      <td>1.048850</td>\n",
       "      <td>1.051087</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.686046</td>\n",
       "      <td>0.694818</td>\n",
       "      <td>0.696336</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.064524</td>\n",
       "      <td>0.482163</td>\n",
       "      <td>0.483124</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.783801</td>\n",
       "      <td>0.406427</td>\n",
       "      <td>0.407937</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.647132</td>\n",
       "      <td>0.579048</td>\n",
       "      <td>0.579392</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.571525</td>\n",
       "      <td>0.419059</td>\n",
       "      <td>0.420335</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.505949</td>\n",
       "      <td>0.424999</td>\n",
       "      <td>0.426782</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.456313</td>\n",
       "      <td>0.288795</td>\n",
       "      <td>0.289603</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.410149</td>\n",
       "      <td>0.244861</td>\n",
       "      <td>0.245197</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.385983</td>\n",
       "      <td>0.298001</td>\n",
       "      <td>0.298132</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.357280</td>\n",
       "      <td>0.230570</td>\n",
       "      <td>0.230744</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.336926</td>\n",
       "      <td>0.226858</td>\n",
       "      <td>0.227108</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.317217</td>\n",
       "      <td>0.222767</td>\n",
       "      <td>0.223056</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.313049</td>\n",
       "      <td>0.242922</td>\n",
       "      <td>0.243250</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.304487</td>\n",
       "      <td>0.257095</td>\n",
       "      <td>0.257347</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.302946</td>\n",
       "      <td>0.225048</td>\n",
       "      <td>0.225364</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.293163</td>\n",
       "      <td>0.270630</td>\n",
       "      <td>0.270969</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.289145</td>\n",
       "      <td>0.235885</td>\n",
       "      <td>0.236129</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.293947</td>\n",
       "      <td>0.229180</td>\n",
       "      <td>0.229497</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.285387</td>\n",
       "      <td>0.235145</td>\n",
       "      <td>0.235459</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.286796</td>\n",
       "      <td>0.252150</td>\n",
       "      <td>0.252284</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.290696</td>\n",
       "      <td>0.286199</td>\n",
       "      <td>0.286415</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.286416</td>\n",
       "      <td>0.224146</td>\n",
       "      <td>0.224525</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.280708</td>\n",
       "      <td>0.224770</td>\n",
       "      <td>0.225020</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.277719</td>\n",
       "      <td>0.229831</td>\n",
       "      <td>0.230121</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.269934</td>\n",
       "      <td>0.229441</td>\n",
       "      <td>0.229708</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.277818</td>\n",
       "      <td>0.228622</td>\n",
       "      <td>0.229061</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.271170</td>\n",
       "      <td>0.223276</td>\n",
       "      <td>0.223455</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.269598</td>\n",
       "      <td>0.243790</td>\n",
       "      <td>0.244002</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.262963</td>\n",
       "      <td>0.230012</td>\n",
       "      <td>0.230267</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.263637</td>\n",
       "      <td>0.244468</td>\n",
       "      <td>0.244630</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.257951</td>\n",
       "      <td>0.256689</td>\n",
       "      <td>0.257018</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.261651</td>\n",
       "      <td>0.249265</td>\n",
       "      <td>0.249362</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.266756</td>\n",
       "      <td>0.252889</td>\n",
       "      <td>0.253086</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.265480</td>\n",
       "      <td>0.223469</td>\n",
       "      <td>0.223718</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.260054</td>\n",
       "      <td>0.276004</td>\n",
       "      <td>0.276272</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.255366</td>\n",
       "      <td>0.236626</td>\n",
       "      <td>0.236818</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.258320</td>\n",
       "      <td>0.222880</td>\n",
       "      <td>0.223131</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.253681</td>\n",
       "      <td>0.253060</td>\n",
       "      <td>0.253185</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.258915</td>\n",
       "      <td>0.218885</td>\n",
       "      <td>0.219104</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.253352</td>\n",
       "      <td>0.216653</td>\n",
       "      <td>0.216926</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.248850</td>\n",
       "      <td>0.218319</td>\n",
       "      <td>0.218533</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='20' class='' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      66.67% [20/30 00:01<00:00 0.2456]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_trial = optuna.create_trial(value=42, params=my_params, distributions=best.distributions)\n",
    "\n",
    "train_cross_valid(my_trial, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97536ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python38564bitfastaicondad52d12c5a30a4725bf9d3e235cf1271c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
