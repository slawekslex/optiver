{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tutorial-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "synthetic-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import lightgbm as lgb\n",
    "from optiver_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "legislative-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_ffill_feat.csv')\n",
    "#train_df = generate_train_df(True, True)\n",
    "\n",
    "#train_df.to_csv('train_ffill_feat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tired-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ids = train_df.time_id.unique()\n",
    "\n",
    "np.random.shuffle(time_ids)\n",
    "\n",
    "splt = int(len(time_ids)*.6)\n",
    "t_ids, v_ids = time_ids[:splt], time_ids[splt:]\n",
    "\n",
    "test_df = train_df[train_df.time_id.isin( v_ids)]\n",
    "train_df = train_df[train_df.time_id.isin( t_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "standing-disclosure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257355, 171577)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "composed-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_targets = test_df.target.to_numpy()\n",
    "test_df = test_df.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "rising-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sizes = {'stock_id':16, 'time_id':16}\n",
    "lin_sizes = [100, 50, 20]\n",
    "ps=0#[.2,.1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-credit",
   "metadata": {},
   "source": [
    "## Generate predictions for pseudo labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "technological-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe_np(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe_np(y_true, y_pred), False\n",
    "def train_models(train):\n",
    "    # Hyperparammeters (optimized)\n",
    "    seed = 29\n",
    "    params = {\n",
    "        'learning_rate': 0.1,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 4,\n",
    "        'seed': seed,\n",
    "        'feature_fraction_seed': seed,\n",
    "        'bagging_seed': seed,\n",
    "        'drop_seed': seed,\n",
    "        'data_random_seed': seed,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "    }   \n",
    "    \n",
    "    # Split features and target\n",
    "    x = train.drop(['row_id', 'target', 'time_id'], axis = 1)\n",
    "    y = train['target']\n",
    "    # Transform stock id to a numeric value\n",
    "    x['stock_id'] = x['stock_id'].astype(int)\n",
    "    models =[]\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = GroupKFold()\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(x, groups = train.time_id)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x.iloc[trn_ind], x.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train, y_train, weight = train_weights, categorical_feature = ['stock_id'])\n",
    "        val_dataset = lgb.Dataset(x_val, y_val, weight = val_weights, categorical_feature = ['stock_id'])\n",
    "        model = lgb.train(params = params, \n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          num_boost_round = 3000, \n",
    "                          early_stopping_rounds = 25, \n",
    "                          verbose_eval = 100,\n",
    "                          feval = feval_rmspe)\n",
    "        models.append(model)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val)\n",
    "        # Predict the test set\n",
    "        #test_predictions += model.predict(x_test) / 10\n",
    "        \n",
    "    rmspe_score = rmspe_np(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    # Return test predictions\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "endless-explorer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.000472622\ttraining's RMSPE: 0.215912\tvalid_1's rmse: 0.000518295\tvalid_1's RMSPE: 0.242341\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's rmse: 0.000463083\ttraining's RMSPE: 0.211554\tvalid_1's rmse: 0.000516522\tvalid_1's RMSPE: 0.241512\n",
      "Training fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.000471277\ttraining's RMSPE: 0.215766\tvalid_1's rmse: 0.000506455\tvalid_1's RMSPE: 0.234824\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's rmse: 0.000465585\ttraining's RMSPE: 0.21316\tvalid_1's rmse: 0.000505427\tvalid_1's RMSPE: 0.234347\n",
      "Training fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.000471822\ttraining's RMSPE: 0.217686\tvalid_1's rmse: 0.000507901\tvalid_1's RMSPE: 0.228253\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's rmse: 0.000462135\ttraining's RMSPE: 0.213217\tvalid_1's rmse: 0.000506469\tvalid_1's RMSPE: 0.227609\n",
      "Training fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.000473019\ttraining's RMSPE: 0.215606\tvalid_1's rmse: 0.000492199\tvalid_1's RMSPE: 0.232096\n",
      "[200]\ttraining's rmse: 0.000448813\ttraining's RMSPE: 0.204573\tvalid_1's rmse: 0.00049159\tvalid_1's RMSPE: 0.231809\n",
      "Early stopping, best iteration is:\n",
      "[183]\ttraining's rmse: 0.000451977\ttraining's RMSPE: 0.206015\tvalid_1's rmse: 0.000490872\tvalid_1's RMSPE: 0.231471\n",
      "Training fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.000467503\ttraining's RMSPE: 0.21651\tvalid_1's rmse: 0.000510799\tvalid_1's RMSPE: 0.22586\n",
      "[200]\ttraining's rmse: 0.000445351\ttraining's RMSPE: 0.206251\tvalid_1's rmse: 0.000507547\tvalid_1's RMSPE: 0.224422\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttraining's rmse: 0.000446096\ttraining's RMSPE: 0.206596\tvalid_1's rmse: 0.000507269\tvalid_1's RMSPE: 0.2243\n",
      "Our out of folds RMSPE is 0.231917674478357\n"
     ]
    }
   ],
   "source": [
    "models = train_models(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wired-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_lgb(test_df, models):\n",
    "    test_df = test_df.drop(['row_id', 'time_id'], axis=1)\n",
    "    res = np.zeros(len(test_df))\n",
    "    for model in models:\n",
    "        preds = model.predict(test_df)\n",
    "        res += preds / 5\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "legal-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo = pred_lgb(test_df, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "authentic-carroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2246709295068485"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = rmspe_np(real_test_targets, pseudo)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-bible",
   "metadata": {},
   "source": [
    "## Train embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "eligible-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_pseudo = test_df.copy()\n",
    "test_with_pseudo['target'] = pseudo\n",
    "train_pseudo = pd.concat([train_df, test_with_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "partial-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pseudo = train_pseudo.drop(['row_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "sporting-meeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stock_id', 'time_id']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_nn,cat_nn = cont_cat_split(train_pseudo, max_card=9000, dep_var='target')\n",
    "cat_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "another-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorify = Categorify()\n",
    "procs_nn = [categorify, FillMissing, Normalize]\n",
    "splits = RandomSplitter()(train_pseudo)\n",
    "to_nn = TabularPandas(train_pseudo, procs_nn, cat_nn, cont_nn,\n",
    "                      splits=splits, y_names='target')\n",
    "\n",
    "dls = to_nn.dataloaders(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "sensitive-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(preds, targs):\n",
    "    x = (targs-preds)/targs\n",
    "    return (x**2).mean().sqrt()\n",
    "\n",
    "config={'lin_first':True, 'ps':ps, 'embed_p':0.5, }\n",
    "learn = tabular_learner(dls, y_range=(0,.1), layers=lin_sizes, \n",
    "                        emb_szs=emb_sizes, \n",
    "                        n_out=1, loss_func = rmspe, metrics=AccumMetric(rmspe), config=config,wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "specialized-tension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.909177</td>\n",
       "      <td>1.180899</td>\n",
       "      <td>1.188217</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.208080</td>\n",
       "      <td>0.185592</td>\n",
       "      <td>0.187282</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.174738</td>\n",
       "      <td>0.212384</td>\n",
       "      <td>0.383939</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179518</td>\n",
       "      <td>0.182434</td>\n",
       "      <td>0.202771</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.163956</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>0.157489</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159554</td>\n",
       "      <td>0.153312</td>\n",
       "      <td>0.153502</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.154794</td>\n",
       "      <td>0.150156</td>\n",
       "      <td>0.150343</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.153365</td>\n",
       "      <td>0.149699</td>\n",
       "      <td>0.149872</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(8, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "framed-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learn.model.embeds[0].weight.data, 'stock_embed.pt')\n",
    "torch.save(learn.model.embeds[1].weight.data, 'time_embed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "seventh-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = dls.test_dl(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "intense-remains",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds,_ = learn.get_preds(dl = test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "present-prediction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6033, dtype=torch.float64)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(test_preds.view(-1), torch.tensor(real_test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "assisted-vienna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3903, dtype=torch.float64)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(test_preds.view(-1), torch.tensor(pseudo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-exhaust",
   "metadata": {},
   "source": [
    "## Train with pretrained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "correct-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCategorify(Categorify):\n",
    "    def setups(self, to):\n",
    "        pass\n",
    "categorify2 = MyCategorify()\n",
    "categorify2.classes = categorify.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "embedded-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(splits):\n",
    "    cont_nn,cat_nn = cont_cat_split(train_df, max_card=9000, dep_var='target')\n",
    "    cat_nn.remove('row_id')\n",
    "    procs_nn = [categorify2, FillMissing, Normalize]\n",
    "    \n",
    "    to_nn = TabularPandas(train_df, procs_nn, cat_nn, cont_nn,\n",
    "                      splits=[list(splits[0]), list(splits[1])], y_names='target')\n",
    "\n",
    "    dls = to_nn.dataloaders(1024)\n",
    "    config={'lin_first':True, 'ps':ps, 'embed_p':0.5, }\n",
    "    learn = tabular_learner(dls, y_range=(0,.1), layers=lin_sizes,\n",
    "                        emb_szs=emb_sizes, \n",
    "                        n_out=1, loss_func = rmspe, metrics=AccumMetric(rmspe), config=config,wd=0)\n",
    "    learn.model.embeds[0].weight.data[:,:]=torch.load( 'stock_embed.pt')\n",
    "    learn.model.embeds[1].weight.data[:,:]=torch.load( 'time_embed.pt')\n",
    "    learn.model.embeds[0].requires_grad_(False)\n",
    "    learn.model.embeds[1].requires_grad_(False)\n",
    "    learn.fit_one_cycle(20, 5e-3)\n",
    "    test_dl = dls.test_dl(test_df)\n",
    "    test_preds,_ = learn.get_preds(dl = test_dl)\n",
    "    print(rmspe(test_preds.view(-1), torch.tensor(real_test_targets)))\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "indonesian-bruce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.347883</td>\n",
       "      <td>6.597923</td>\n",
       "      <td>6.664089</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.795744</td>\n",
       "      <td>1.554739</td>\n",
       "      <td>1.562973</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.061178</td>\n",
       "      <td>0.536698</td>\n",
       "      <td>0.565613</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.789233</td>\n",
       "      <td>0.341136</td>\n",
       "      <td>0.448057</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.243430</td>\n",
       "      <td>0.201926</td>\n",
       "      <td>0.204889</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.306893</td>\n",
       "      <td>0.233807</td>\n",
       "      <td>0.240153</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.238646</td>\n",
       "      <td>0.208667</td>\n",
       "      <td>0.216151</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.227316</td>\n",
       "      <td>0.204898</td>\n",
       "      <td>0.209271</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.218624</td>\n",
       "      <td>0.197215</td>\n",
       "      <td>0.201488</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.215175</td>\n",
       "      <td>0.199942</td>\n",
       "      <td>0.203095</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.209444</td>\n",
       "      <td>0.196471</td>\n",
       "      <td>0.203589</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.203734</td>\n",
       "      <td>0.204761</td>\n",
       "      <td>0.207010</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.198685</td>\n",
       "      <td>0.187081</td>\n",
       "      <td>0.189711</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.196290</td>\n",
       "      <td>0.186327</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.195489</td>\n",
       "      <td>0.187104</td>\n",
       "      <td>0.190445</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.193661</td>\n",
       "      <td>0.185349</td>\n",
       "      <td>0.188001</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.194945</td>\n",
       "      <td>0.185218</td>\n",
       "      <td>0.188021</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.191580</td>\n",
       "      <td>0.184928</td>\n",
       "      <td>0.187482</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.192294</td>\n",
       "      <td>0.186030</td>\n",
       "      <td>0.190133</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.190933</td>\n",
       "      <td>0.184561</td>\n",
       "      <td>0.187511</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2220, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.971078</td>\n",
       "      <td>6.318727</td>\n",
       "      <td>6.404065</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.865655</td>\n",
       "      <td>1.304353</td>\n",
       "      <td>1.338313</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.960066</td>\n",
       "      <td>0.893656</td>\n",
       "      <td>0.908531</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.260857</td>\n",
       "      <td>0.216662</td>\n",
       "      <td>0.220812</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.225708</td>\n",
       "      <td>0.207939</td>\n",
       "      <td>0.211902</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.216992</td>\n",
       "      <td>0.214709</td>\n",
       "      <td>0.218727</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.228172</td>\n",
       "      <td>0.252215</td>\n",
       "      <td>0.262160</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.215989</td>\n",
       "      <td>0.205325</td>\n",
       "      <td>0.209430</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.209702</td>\n",
       "      <td>0.202746</td>\n",
       "      <td>0.206781</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.203854</td>\n",
       "      <td>0.193048</td>\n",
       "      <td>0.196501</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.205693</td>\n",
       "      <td>0.202675</td>\n",
       "      <td>0.207020</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.195452</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.194858</td>\n",
       "      <td>0.192655</td>\n",
       "      <td>0.197272</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.193641</td>\n",
       "      <td>0.190319</td>\n",
       "      <td>0.194284</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.292688</td>\n",
       "      <td>0.194994</td>\n",
       "      <td>0.198350</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.193228</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>0.191188</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.190547</td>\n",
       "      <td>0.188648</td>\n",
       "      <td>0.192348</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.189651</td>\n",
       "      <td>0.188787</td>\n",
       "      <td>0.192394</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.188918</td>\n",
       "      <td>0.187786</td>\n",
       "      <td>0.191160</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.189946</td>\n",
       "      <td>0.187871</td>\n",
       "      <td>0.191334</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2218, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.605020</td>\n",
       "      <td>7.138633</td>\n",
       "      <td>7.198597</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.789817</td>\n",
       "      <td>1.301170</td>\n",
       "      <td>1.352451</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.007821</td>\n",
       "      <td>0.429325</td>\n",
       "      <td>0.443874</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.424229</td>\n",
       "      <td>0.346194</td>\n",
       "      <td>0.367595</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.233216</td>\n",
       "      <td>0.217438</td>\n",
       "      <td>0.233004</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.216692</td>\n",
       "      <td>0.206241</td>\n",
       "      <td>0.209007</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.217660</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.204767</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.215639</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.205034</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.213305</td>\n",
       "      <td>0.193577</td>\n",
       "      <td>0.198098</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.207601</td>\n",
       "      <td>0.196065</td>\n",
       "      <td>0.201284</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.209421</td>\n",
       "      <td>0.193793</td>\n",
       "      <td>0.198922</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.204493</td>\n",
       "      <td>0.190146</td>\n",
       "      <td>0.195426</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.211333</td>\n",
       "      <td>0.200375</td>\n",
       "      <td>0.204313</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.201845</td>\n",
       "      <td>0.191974</td>\n",
       "      <td>0.198390</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.198682</td>\n",
       "      <td>0.189254</td>\n",
       "      <td>0.191654</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.201685</td>\n",
       "      <td>0.186708</td>\n",
       "      <td>0.190206</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.197694</td>\n",
       "      <td>0.185255</td>\n",
       "      <td>0.187590</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.197694</td>\n",
       "      <td>0.184818</td>\n",
       "      <td>0.187155</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.197675</td>\n",
       "      <td>0.184521</td>\n",
       "      <td>0.186819</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.196103</td>\n",
       "      <td>0.184861</td>\n",
       "      <td>0.187201</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2234, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.936513</td>\n",
       "      <td>7.995620</td>\n",
       "      <td>8.073772</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.174969</td>\n",
       "      <td>1.184907</td>\n",
       "      <td>1.248181</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.371408</td>\n",
       "      <td>0.737983</td>\n",
       "      <td>0.877382</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.481981</td>\n",
       "      <td>0.294406</td>\n",
       "      <td>0.298590</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.240185</td>\n",
       "      <td>0.213382</td>\n",
       "      <td>0.217829</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.227674</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>0.212193</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.227555</td>\n",
       "      <td>0.215756</td>\n",
       "      <td>0.217975</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.217888</td>\n",
       "      <td>0.211231</td>\n",
       "      <td>0.213747</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.211594</td>\n",
       "      <td>0.196112</td>\n",
       "      <td>0.198886</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.223228</td>\n",
       "      <td>0.209739</td>\n",
       "      <td>0.221576</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.220936</td>\n",
       "      <td>0.210660</td>\n",
       "      <td>0.218940</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.210534</td>\n",
       "      <td>0.195538</td>\n",
       "      <td>0.198344</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.201338</td>\n",
       "      <td>0.194451</td>\n",
       "      <td>0.196725</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.200604</td>\n",
       "      <td>0.193541</td>\n",
       "      <td>0.196687</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.194427</td>\n",
       "      <td>0.189339</td>\n",
       "      <td>0.191233</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.194442</td>\n",
       "      <td>0.192575</td>\n",
       "      <td>0.195826</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.194224</td>\n",
       "      <td>0.187562</td>\n",
       "      <td>0.189624</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.190630</td>\n",
       "      <td>0.187302</td>\n",
       "      <td>0.189278</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.191799</td>\n",
       "      <td>0.187344</td>\n",
       "      <td>0.189390</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.194190</td>\n",
       "      <td>0.186990</td>\n",
       "      <td>0.188962</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2234, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.731443</td>\n",
       "      <td>7.884107</td>\n",
       "      <td>7.931853</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.038719</td>\n",
       "      <td>1.615034</td>\n",
       "      <td>1.665258</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.509527</td>\n",
       "      <td>0.248750</td>\n",
       "      <td>0.251453</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.231211</td>\n",
       "      <td>0.205593</td>\n",
       "      <td>0.207968</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208365</td>\n",
       "      <td>0.216445</td>\n",
       "      <td>0.224988</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.230820</td>\n",
       "      <td>0.215485</td>\n",
       "      <td>0.223330</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.211077</td>\n",
       "      <td>0.195879</td>\n",
       "      <td>0.197682</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.204396</td>\n",
       "      <td>0.191683</td>\n",
       "      <td>0.193619</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.201782</td>\n",
       "      <td>0.193330</td>\n",
       "      <td>0.195815</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.207735</td>\n",
       "      <td>0.190188</td>\n",
       "      <td>0.193866</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.198789</td>\n",
       "      <td>0.184496</td>\n",
       "      <td>0.186135</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.200415</td>\n",
       "      <td>0.185951</td>\n",
       "      <td>0.187802</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.195620</td>\n",
       "      <td>0.187484</td>\n",
       "      <td>0.194406</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.195191</td>\n",
       "      <td>0.185595</td>\n",
       "      <td>0.187837</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.193324</td>\n",
       "      <td>0.182098</td>\n",
       "      <td>0.184084</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.192837</td>\n",
       "      <td>0.183109</td>\n",
       "      <td>0.184873</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.190992</td>\n",
       "      <td>0.186392</td>\n",
       "      <td>0.193175</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.190908</td>\n",
       "      <td>0.185605</td>\n",
       "      <td>0.192642</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.191240</td>\n",
       "      <td>0.185442</td>\n",
       "      <td>0.192176</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.190861</td>\n",
       "      <td>0.185754</td>\n",
       "      <td>0.192762</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2222, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "kfold = GroupKFold(n_splits = 5)\n",
    "preds=[]\n",
    "for split in kfold.split(train_df, groups=train_df.time_id):\n",
    "    preds.append(train_fold(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "imported-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp =torch.cat(preds, dim=1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "received-headquarters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2218, dtype=torch.float64)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score =rmspe(mp, torch.tensor(real_test_targets))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "guided-gospel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2218, dtype=torch.float64),\n",
       " 0.2246709295068485,\n",
       " tensor(1.2798, dtype=torch.float64))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, baseline, 100* (baseline-score)/baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "completed-decrease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0467, dtype=torch.float64)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(mp, torch.tensor(pseudo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-cache",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-yellow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-lloyd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-montreal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python38564bitfastaicondad52d12c5a30a4725bf9d3e235cf1271c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
