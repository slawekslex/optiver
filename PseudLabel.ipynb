{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1b3383",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0cf7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import lightgbm as lgb\n",
    "from optiver_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a20fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_ffill_feat.csv')\n",
    "#train_df = generate_train_df(True, True)\n",
    "\n",
    "#train_df.to_csv('train_ffill_feat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854737df",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ids = train_df.time_id.unique()\n",
    "\n",
    "np.random.shuffle(time_ids)\n",
    "\n",
    "splt = int(len(time_ids)*.6)\n",
    "t_ids, v_ids = time_ids[:splt], time_ids[splt:]\n",
    "\n",
    "test_df = train_df[train_df.time_id.isin( v_ids)]\n",
    "train_df = train_df[train_df.time_id.isin( t_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e62de8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257359, 171573)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce91ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_targets = test_df.target.to_numpy()\n",
    "test_df = test_df.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06d8b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sizes = {'stock_id':10, 'time_id':10}\n",
    "lin_sizes = [100, 50, 20]\n",
    "\n",
    "ps=0#[.2,.1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd300f",
   "metadata": {},
   "source": [
    "## Generate predictions for pseudo labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "384abc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe_np(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "def feval_rmspe(y_pred, lgb_train):\n",
    "    y_true = lgb_train.get_label()\n",
    "    return 'RMSPE', rmspe_np(y_true, y_pred), False\n",
    "def train_models(train):\n",
    "    # Hyperparammeters (optimized)\n",
    "    seed = 29\n",
    "    params = {\n",
    "        'learning_rate': 0.1,        \n",
    "        'lambda_l1': 2,\n",
    "        'lambda_l2': 7,\n",
    "        'num_leaves': 800,\n",
    "        'min_sum_hessian_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_bynode': 0.8,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 42,\n",
    "        'min_data_in_leaf': 700,\n",
    "        'max_depth': 4,\n",
    "        'seed': seed,\n",
    "        'feature_fraction_seed': seed,\n",
    "        'bagging_seed': seed,\n",
    "        'drop_seed': seed,\n",
    "        'data_random_seed': seed,\n",
    "        'objective': 'rmse',\n",
    "        'boosting': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "    }   \n",
    "    \n",
    "    # Split features and target\n",
    "    x = train.drop(['row_id', 'target', 'time_id'], axis = 1)\n",
    "    y = train['target']\n",
    "    # Transform stock id to a numeric value\n",
    "    x['stock_id'] = x['stock_id'].astype(int)\n",
    "    models =[]\n",
    "    # Create out of folds array\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    # Create a KFold object\n",
    "    kfold = GroupKFold()\n",
    "    # Iterate through each fold\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(x, groups = train.time_id)):\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x.iloc[trn_ind], x.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        # Root mean squared percentage error weights\n",
    "        train_weights = 1 / np.square(y_train)\n",
    "        val_weights = 1 / np.square(y_val)\n",
    "        train_dataset = lgb.Dataset(x_train, y_train, weight = train_weights, categorical_feature = ['stock_id'])\n",
    "        val_dataset = lgb.Dataset(x_val, y_val, weight = val_weights, categorical_feature = ['stock_id'])\n",
    "        model = lgb.train(params = params, \n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          num_boost_round = 3000, \n",
    "                          early_stopping_rounds = 25, \n",
    "                          verbose_eval = 100,\n",
    "                          feval = feval_rmspe)\n",
    "        models.append(model)\n",
    "        # Add predictions to the out of folds array\n",
    "        oof_predictions[val_ind] = model.predict(x_val)\n",
    "        # Predict the test set\n",
    "        #test_predictions += model.predict(x_test) / 10\n",
    "        \n",
    "    rmspe_score = rmspe_np(y, oof_predictions)\n",
    "    print(f'Our out of folds RMSPE is {rmspe_score}')\n",
    "    # Return test predictions\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa22a8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.00046983\ttraining's RMSPE: 0.216064\tvalid_1's rmse: 0.000484415\tvalid_1's RMSPE: 0.226707\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's rmse: 0.000459417\ttraining's RMSPE: 0.211276\tvalid_1's rmse: 0.000482476\tvalid_1's RMSPE: 0.225799\n",
      "Training fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.000462288\ttraining's RMSPE: 0.215112\tvalid_1's rmse: 0.000512425\tvalid_1's RMSPE: 0.228527\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's rmse: 0.000455945\ttraining's RMSPE: 0.21216\tvalid_1's rmse: 0.00051163\tvalid_1's RMSPE: 0.228172\n",
      "Training fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.000468826\ttraining's RMSPE: 0.214428\tvalid_1's rmse: 0.000487063\tvalid_1's RMSPE: 0.232669\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttraining's rmse: 0.000460842\ttraining's RMSPE: 0.210776\tvalid_1's rmse: 0.000486162\tvalid_1's RMSPE: 0.232239\n",
      "Training fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.000468934\ttraining's RMSPE: 0.216469\tvalid_1's rmse: 0.000514907\tvalid_1's RMSPE: 0.237413\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's rmse: 0.000456775\ttraining's RMSPE: 0.210857\tvalid_1's rmse: 0.00051316\tvalid_1's RMSPE: 0.236608\n",
      "Training fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds\n",
      "[100]\ttraining's rmse: 0.000463462\ttraining's RMSPE: 0.214735\tvalid_1's rmse: 0.000509313\tvalid_1's RMSPE: 0.231309\n",
      "[200]\ttraining's rmse: 0.000440312\ttraining's RMSPE: 0.20401\tvalid_1's rmse: 0.000506524\tvalid_1's RMSPE: 0.230042\n",
      "Early stopping, best iteration is:\n",
      "[234]\ttraining's rmse: 0.000435972\ttraining's RMSPE: 0.201999\tvalid_1's rmse: 0.000505486\tvalid_1's RMSPE: 0.22957\n",
      "Our out of folds RMSPE is 0.23050988799649366\n"
     ]
    }
   ],
   "source": [
    "models = train_models(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f7290ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_lgb(test_df, models):\n",
    "    test_df = test_df.drop(['row_id', 'time_id'], axis=1)\n",
    "    res = np.zeros(len(test_df))\n",
    "    for model in models:\n",
    "        preds = model.predict(test_df)\n",
    "        res += preds / 5\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4717d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo = pred_lgb(test_df, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8c37c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22569155599349788"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = rmspe_np(real_test_targets, pseudo)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59baa9c0",
   "metadata": {},
   "source": [
    "## Train embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cebaf070",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pseudo = generate_train_df(False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02b03eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pseudo.loc[train_pseudo.time_id.isin( v_ids), 'target'] = pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "59923665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_with_pseudo = test_df.copy()\n",
    "# test_with_pseudo['target'] = mp#pseudo\n",
    "# train_pseudo = pd.concat([train_df, test_with_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60e6940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pseudo = train_pseudo.drop(['row_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09985c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stock_id', 'time_id']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_nn,cat_nn = cont_cat_split(train_pseudo, max_card=9000, dep_var='target')\n",
    "cat_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78ee5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorify = Categorify()\n",
    "procs_nn = [categorify, FillMissing, Normalize]\n",
    "splits = RandomSplitter()(train_pseudo)\n",
    "to_nn = TabularPandas(train_pseudo, procs_nn, cat_nn, cont_nn,\n",
    "                      splits=splits, y_names='target')\n",
    "\n",
    "dls = to_nn.dataloaders(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "799fd5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(preds, targs):\n",
    "    x = (targs-preds)/targs\n",
    "    return (x**2).mean().sqrt()\n",
    "\n",
    "config={'lin_first':True, 'ps':ps, 'embed_p':0.5, }\n",
    "learn = tabular_learner(dls, y_range=(0,.1), layers=lin_sizes, \n",
    "                        emb_szs=emb_sizes, \n",
    "                        n_out=1, loss_func = rmspe, metrics=AccumMetric(rmspe), config=config,wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca744104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.776543</td>\n",
       "      <td>1.875637</td>\n",
       "      <td>1.882712</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.346720</td>\n",
       "      <td>0.270600</td>\n",
       "      <td>0.432115</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231727</td>\n",
       "      <td>0.203746</td>\n",
       "      <td>0.203940</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.207089</td>\n",
       "      <td>0.286130</td>\n",
       "      <td>0.443295</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.179497</td>\n",
       "      <td>0.160414</td>\n",
       "      <td>0.160662</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.169046</td>\n",
       "      <td>0.154829</td>\n",
       "      <td>0.155008</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.164082</td>\n",
       "      <td>0.154424</td>\n",
       "      <td>0.154609</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.164113</td>\n",
       "      <td>0.153509</td>\n",
       "      <td>0.153691</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(8, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9eda6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learn.model.embeds[0].weight.data, 'stock_embed.pt')\n",
    "torch.save(learn.model.embeds[1].weight.data, 'time_embed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b103d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = dls.test_dl(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bec5bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds,_ = learn.get_preds(dl = test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22aac26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2261, dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(test_preds.view(-1), torch.tensor(real_test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d945e551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0530, dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(test_preds.view(-1), torch.tensor(pseudo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e1e7e",
   "metadata": {},
   "source": [
    "## Train with pretrained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bde71b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCategorify(Categorify):\n",
    "    def setups(self, to):\n",
    "        pass\n",
    "categorify2 = MyCategorify()\n",
    "categorify2.classes = categorify.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8bc43a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(splits):\n",
    "    #train_df = train_pseudo.loc[train_pseudo.time_id.isin( t_ids)]\n",
    "    \n",
    "    cont_nn,cat_nn = cont_cat_split(train_df, max_card=9000, dep_var='target')\n",
    "    cat_nn.remove('row_id')\n",
    "    procs_nn = [categorify2, FillMissing, Normalize]\n",
    "    \n",
    "    to_nn = TabularPandas(train_df, procs_nn, cat_nn, cont_nn,\n",
    "                      splits=[list(splits[0]), list(splits[1])], y_names='target')\n",
    "\n",
    "    dls = to_nn.dataloaders(1024)\n",
    "    config={'lin_first':True, 'ps':ps, 'embed_p':0.5, }\n",
    "    learn = tabular_learner(dls, y_range=(0,.1), layers=lin_sizes,\n",
    "                        emb_szs=emb_sizes, \n",
    "                        n_out=1, loss_func = rmspe, metrics=AccumMetric(rmspe), config=config,wd=0)\n",
    "    learn.model.embeds[0].weight.data[:,:]=torch.load( 'stock_embed.pt')\n",
    "    learn.model.embeds[1].weight.data[:,:]=torch.load( 'time_embed.pt')\n",
    "    learn.model.embeds[0].requires_grad_(False)\n",
    "    learn.model.embeds[1].requires_grad_(False)\n",
    "    learn.fit_one_cycle(20, 5e-3)\n",
    "    test_dl = dls.test_dl(test_df)\n",
    "    test_preds,_ = learn.get_preds(dl = test_dl)\n",
    "    print(rmspe(test_preds.view(-1), torch.tensor(real_test_targets)))\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45486c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.260633</td>\n",
       "      <td>4.965076</td>\n",
       "      <td>5.054761</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.265727</td>\n",
       "      <td>1.333321</td>\n",
       "      <td>1.367008</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.467597</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.336972</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.235599</td>\n",
       "      <td>0.214093</td>\n",
       "      <td>0.218488</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.219467</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.210479</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.212929</td>\n",
       "      <td>0.205836</td>\n",
       "      <td>0.208615</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.211921</td>\n",
       "      <td>0.201236</td>\n",
       "      <td>0.203816</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.206616</td>\n",
       "      <td>0.193946</td>\n",
       "      <td>0.198114</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.228528</td>\n",
       "      <td>0.205280</td>\n",
       "      <td>0.209597</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.203995</td>\n",
       "      <td>0.191156</td>\n",
       "      <td>0.193691</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.200897</td>\n",
       "      <td>0.189365</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.200536</td>\n",
       "      <td>0.195144</td>\n",
       "      <td>0.198045</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.198804</td>\n",
       "      <td>0.188238</td>\n",
       "      <td>0.190990</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.196136</td>\n",
       "      <td>0.187222</td>\n",
       "      <td>0.189896</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.194072</td>\n",
       "      <td>0.186101</td>\n",
       "      <td>0.188471</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.191521</td>\n",
       "      <td>0.185699</td>\n",
       "      <td>0.188029</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.191774</td>\n",
       "      <td>0.185618</td>\n",
       "      <td>0.187972</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.191123</td>\n",
       "      <td>0.184778</td>\n",
       "      <td>0.187025</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.190664</td>\n",
       "      <td>0.184551</td>\n",
       "      <td>0.186807</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.191128</td>\n",
       "      <td>0.184275</td>\n",
       "      <td>0.186548</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2209, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.487132</td>\n",
       "      <td>5.413876</td>\n",
       "      <td>5.504634</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.136081</td>\n",
       "      <td>1.865705</td>\n",
       "      <td>1.877349</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.457945</td>\n",
       "      <td>0.281688</td>\n",
       "      <td>0.284188</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.248202</td>\n",
       "      <td>0.213600</td>\n",
       "      <td>0.220654</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.218973</td>\n",
       "      <td>0.201338</td>\n",
       "      <td>0.206023</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.215233</td>\n",
       "      <td>0.238621</td>\n",
       "      <td>0.319671</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.231235</td>\n",
       "      <td>0.205885</td>\n",
       "      <td>0.214453</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.219331</td>\n",
       "      <td>0.206491</td>\n",
       "      <td>0.215180</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.219069</td>\n",
       "      <td>0.201514</td>\n",
       "      <td>0.204642</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.215311</td>\n",
       "      <td>0.197294</td>\n",
       "      <td>0.200083</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.216482</td>\n",
       "      <td>0.357010</td>\n",
       "      <td>0.779765</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.222986</td>\n",
       "      <td>0.219281</td>\n",
       "      <td>0.283886</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.206305</td>\n",
       "      <td>0.396706</td>\n",
       "      <td>1.379323</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.205346</td>\n",
       "      <td>0.192035</td>\n",
       "      <td>0.195003</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.203557</td>\n",
       "      <td>0.191723</td>\n",
       "      <td>0.194330</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.201871</td>\n",
       "      <td>0.192393</td>\n",
       "      <td>0.194606</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.199860</td>\n",
       "      <td>0.188815</td>\n",
       "      <td>0.190888</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.200197</td>\n",
       "      <td>0.408103</td>\n",
       "      <td>1.611296</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.200110</td>\n",
       "      <td>0.187899</td>\n",
       "      <td>0.189844</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.198937</td>\n",
       "      <td>0.187585</td>\n",
       "      <td>0.189590</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2254, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.146356</td>\n",
       "      <td>4.909788</td>\n",
       "      <td>4.997787</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.827811</td>\n",
       "      <td>1.009338</td>\n",
       "      <td>1.015407</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.515664</td>\n",
       "      <td>0.403151</td>\n",
       "      <td>0.408204</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.255362</td>\n",
       "      <td>0.255071</td>\n",
       "      <td>0.259369</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.228149</td>\n",
       "      <td>0.218264</td>\n",
       "      <td>0.223299</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.215151</td>\n",
       "      <td>0.202176</td>\n",
       "      <td>0.206876</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.203988</td>\n",
       "      <td>0.205360</td>\n",
       "      <td>0.209063</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.203365</td>\n",
       "      <td>0.202160</td>\n",
       "      <td>0.205379</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.203264</td>\n",
       "      <td>0.238867</td>\n",
       "      <td>0.420861</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.211262</td>\n",
       "      <td>0.194540</td>\n",
       "      <td>0.198197</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.209107</td>\n",
       "      <td>0.200788</td>\n",
       "      <td>0.204860</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.209688</td>\n",
       "      <td>0.231689</td>\n",
       "      <td>0.234387</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.201291</td>\n",
       "      <td>0.338014</td>\n",
       "      <td>0.852185</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.197901</td>\n",
       "      <td>0.223799</td>\n",
       "      <td>0.290689</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.198122</td>\n",
       "      <td>0.239131</td>\n",
       "      <td>0.366699</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.196735</td>\n",
       "      <td>0.298394</td>\n",
       "      <td>0.701680</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.275818</td>\n",
       "      <td>0.205140</td>\n",
       "      <td>0.231368</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.217046</td>\n",
       "      <td>0.213958</td>\n",
       "      <td>0.255783</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.223482</td>\n",
       "      <td>0.189342</td>\n",
       "      <td>0.192814</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.205308</td>\n",
       "      <td>0.188796</td>\n",
       "      <td>0.191738</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3447, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.356498</td>\n",
       "      <td>5.051651</td>\n",
       "      <td>5.115180</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.946977</td>\n",
       "      <td>0.875455</td>\n",
       "      <td>0.897781</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.863812</td>\n",
       "      <td>0.503872</td>\n",
       "      <td>0.528490</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.334953</td>\n",
       "      <td>0.242866</td>\n",
       "      <td>0.249061</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230773</td>\n",
       "      <td>0.218774</td>\n",
       "      <td>0.224861</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.279226</td>\n",
       "      <td>0.240502</td>\n",
       "      <td>0.248150</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.216067</td>\n",
       "      <td>0.212397</td>\n",
       "      <td>0.217270</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.205242</td>\n",
       "      <td>0.200619</td>\n",
       "      <td>0.208466</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.208118</td>\n",
       "      <td>0.189923</td>\n",
       "      <td>0.192089</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.257397</td>\n",
       "      <td>0.200944</td>\n",
       "      <td>0.210818</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.203533</td>\n",
       "      <td>0.193219</td>\n",
       "      <td>0.195766</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.199575</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.198881</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.200756</td>\n",
       "      <td>0.186880</td>\n",
       "      <td>0.189133</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.196983</td>\n",
       "      <td>0.186264</td>\n",
       "      <td>0.188632</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.195807</td>\n",
       "      <td>0.187750</td>\n",
       "      <td>0.191043</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.195015</td>\n",
       "      <td>0.184797</td>\n",
       "      <td>0.187848</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.193811</td>\n",
       "      <td>0.188431</td>\n",
       "      <td>0.195991</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.192804</td>\n",
       "      <td>0.184895</td>\n",
       "      <td>0.189318</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.193406</td>\n",
       "      <td>0.183321</td>\n",
       "      <td>0.186204</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.191735</td>\n",
       "      <td>0.183583</td>\n",
       "      <td>0.186631</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2222, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.531056</td>\n",
       "      <td>4.574511</td>\n",
       "      <td>4.630472</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.577737</td>\n",
       "      <td>0.784980</td>\n",
       "      <td>0.804030</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.661034</td>\n",
       "      <td>0.417438</td>\n",
       "      <td>0.431712</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.240932</td>\n",
       "      <td>0.222068</td>\n",
       "      <td>0.228761</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.213508</td>\n",
       "      <td>0.208399</td>\n",
       "      <td>0.211297</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.279593</td>\n",
       "      <td>0.289253</td>\n",
       "      <td>0.299979</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.223430</td>\n",
       "      <td>0.202630</td>\n",
       "      <td>0.211454</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.211756</td>\n",
       "      <td>0.251770</td>\n",
       "      <td>0.258401</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.204665</td>\n",
       "      <td>0.216661</td>\n",
       "      <td>0.219560</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.202570</td>\n",
       "      <td>0.191898</td>\n",
       "      <td>0.195227</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.203193</td>\n",
       "      <td>0.198852</td>\n",
       "      <td>0.204145</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.197290</td>\n",
       "      <td>0.190661</td>\n",
       "      <td>0.193081</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.196554</td>\n",
       "      <td>0.185532</td>\n",
       "      <td>0.187641</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.196316</td>\n",
       "      <td>0.196891</td>\n",
       "      <td>0.199133</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.196088</td>\n",
       "      <td>0.186582</td>\n",
       "      <td>0.189134</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.193946</td>\n",
       "      <td>0.185261</td>\n",
       "      <td>0.187490</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.192811</td>\n",
       "      <td>0.185343</td>\n",
       "      <td>0.187383</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.191728</td>\n",
       "      <td>0.184588</td>\n",
       "      <td>0.186643</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.191823</td>\n",
       "      <td>0.184549</td>\n",
       "      <td>0.186579</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.190783</td>\n",
       "      <td>0.184369</td>\n",
       "      <td>0.186379</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2214, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "kfold = GroupKFold(n_splits = 5)\n",
    "preds=[]\n",
    "for split in kfold.split(train_df, groups=train_df.time_id):\n",
    "    preds.append(train_fold(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7322cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp=torch.median(torch.cat(preds, dim=1), dim=1)[0]\n",
    "#mp=torch.mean(torch.cat(preds, dim=1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f2c8510f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2211, dtype=torch.float64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score =rmspe(mp, torch.tensor(real_test_targets))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "337fbbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2211, dtype=torch.float64),\n",
       " 0.22569155599349788,\n",
       " tensor(2.0509, dtype=torch.float64))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, baseline, 100* (baseline-score)/baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "99e911d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0495, dtype=torch.float64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(mp, torch.tensor(pseudo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c5753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e4bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e590d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a58a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python38564bitfastaicondad52d12c5a30a4725bf9d3e235cf1271c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
