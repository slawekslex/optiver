{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5905601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.tabular.all import *\n",
    "from sklearn.model_selection import KFold, GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd7b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../input/optiver-realized-volatility-prediction')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82141fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ftrs = pd.read_feather('train_24cols.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145b969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ftrs['offset']=pd.read_csv(PATH/'train_with_wap.csv').offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c658e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ftrs = train_ftrs.fillna(0)\n",
    "train_ftrs['trade_seconds'] = 'more'\n",
    "\n",
    "\n",
    "\n",
    "for val in range(3): train_ftrs.loc[train_ftrs.seconds_in_bucket_size_0_600==val, 'trade_seconds'] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83982fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.9968e-01, 1.0003e+00, 7.6999e-04, 7.6673e-04, 9.9948e-01, 1.0005e+00,\n",
      "        9.5934e-04, 9.2822e-04]) tensor([0.0037, 0.0037, 0.0054, 0.0050, 0.0037, 0.0037, 0.0067, 0.0057])\n",
      "CPU times: user 14.5 s, sys: 16 s, total: 30.4 s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch_data = torch.load(PATH/'torch_data.pth')\n",
    "\n",
    "\n",
    "\n",
    "means, stds = torch_data.mean(dim=0), torch_data.std(dim=0)\n",
    "print(means, stds)\n",
    "torch_data = (torch_data - means) / stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ee1aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProc(TabularProc):\n",
    "    def encodes(self, to):\n",
    "        print(type(to))\n",
    "        return to\n",
    "    def __getitem__(self,k):\n",
    "        print('getting', k)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da2863fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadBatch(ItemTransform):\n",
    "    def encodes(self, to):\n",
    "        book_offsets = torch.tensor(to['offset'].to_numpy()).long()\n",
    "        book_data = torch_data.view(-1,600,8)[book_offsets//600,:,:]\n",
    "        book_data = book_data.permute(0,2,1)\n",
    "        res = (tensor(to.cats).long(),tensor(to.conts).float(), book_data)        \n",
    "        res = res + (tensor(to.targ),)\n",
    "        if to.device is not None: res = to_device(res, to.device)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3ffef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_idx, val_idx = first(GroupKFold().split(train_ftrs, groups = train_ftrs.time_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab1487f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['log_return2_std_0_600', 'stock_id', 'row_id', 'time_id', 'target',\n",
       "       'log_return_price_std_0_600', 'order_count_sum_0_600',\n",
       "       'seconds_in_bucket_size_0_600', 'size_sum_0_600',\n",
       "       'log_return1_std_0_600_min_time', 'log_return1_std_0_600_mean_time',\n",
       "       'log_return1_std_0_600_min_stock', 'log_return1_std_0_600_mean_stock',\n",
       "       'log_return1_std_0_600', 'log_return1_std_200_600',\n",
       "       'log_return1_std_400_600', 'price_spread_mean_0_600',\n",
       "       'log_return_price_std_0_600_mean_time',\n",
       "       'log_return_price_std_200_600_mean_time',\n",
       "       'log_return_price_std_400_600_mean_time',\n",
       "       'log_return_price_std_0_600_min_time',\n",
       "       'log_return_price_std_200_600_min_time',\n",
       "       'log_return_price_std_400_600_min_time', 'total_volume_mean_0_600',\n",
       "       'offset', 'trade_seconds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ftrs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b019d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['stock_id', 'row_id', 'time_id', 'target',\n",
    "       'log_return_price_std_0_600', 'order_count_sum_0_600',\n",
    "       'seconds_in_bucket_size_0_600', 'size_sum_0_600',\n",
    "       'log_return1_std_0_600_min_time', 'log_return1_std_0_600_mean_time',\n",
    "       'log_return1_std_0_600_min_stock', 'log_return1_std_0_600_mean_stock',\n",
    "       'log_return_price_std_0_600_mean_time',\n",
    "       'log_return_price_std_200_600_mean_time',\n",
    "       'log_return_price_std_400_600_mean_time',\n",
    "       'log_return_price_std_0_600_min_time',\n",
    "       'log_return_price_std_200_600_min_time',\n",
    "       'log_return_price_std_400_600_min_time', 'total_volume_mean_0_600',\n",
    "       'offset', 'trade_seconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7587ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ftrs = train_ftrs[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e2c2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_nn,cat_nn = cont_cat_split(train_ftrs, max_card=9000, dep_var='target')\n",
    "cont_nn.remove('offset')\n",
    "cat_nn=[x for x in cat_nn if not x in ['row_id', 'time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b2e9d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slex/programy/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "procs_nn = [Categorify, FillMissing, Normalize]\n",
    "to_nn = TabularPandas(train_ftrs, procs_nn, cat_nn, cont_nn,\n",
    "                      splits=[list(trn_idx), list(val_idx)], y_names='target')\n",
    "dls = to_nn.dataloaders(1024, after_batch = ReadBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e9bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.conv_layers = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d116180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, layer_sizes, conv_layers, embed_p,ps):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(embed_p)\n",
    "        self.conv_layers = conv_layers\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        sizes = [n_emb + n_cont + 20] + layer_sizes + [1]\n",
    "        actns = [nn.ReLU() for _ in range(len(sizes)-2)] + [None]\n",
    "        layers = [LinBnDrop(sizes[i], sizes[i+1], bn = (i!=len(actns)-1), p=p, act=a, lin_first=True)\n",
    "                       for i,(p,a) in enumerate(zip(ps+[0.],actns))]\n",
    "        layers.append(SigmoidRange(0, 0.1))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    def forward(self, x_cat, x_cont, x_raw):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x_conv = self.conv_layers(x_raw)\n",
    "        x = torch.cat([x, x_cont, x_conv], 1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb3575f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv1d(ch, ch, kernel_size = 5, padding = 2, padding_mode='replicate'),\n",
    "            nn.BatchNorm1d(ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(ch, ch, kernel_size = 5, padding = 2, padding_mode='replicate'),\n",
    "            nn.BatchNorm1d(ch),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.layers(x) + x\n",
    "        res = F.relu(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "716ac2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers =torch.load('models/conv_model.pth', map_location='cpu').conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b8969c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_2way(model):\n",
    "    #return L(params(model.initial_conv)+params(model.conv_layers), params(model.classifier))\n",
    "    return L(params(model.conv_layers), params(model.layers)+params(model.embeds))\n",
    "def rmspe(preds, targs):\n",
    "    x = (targs-preds)/targs\n",
    "    return (x**2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23eeecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sizes = [(len(dls.train.classes['stock_id']), 10),\n",
    "             (len(dls.train.classes['trade_seconds']), 3)]\n",
    "n_cont = len(dls.cont_names)\n",
    "layer_sizes = [500,500,500,200,100]\n",
    "embed_p = .05\n",
    "ps = [0,.1,.1,.1,0]\n",
    "model = ConvModel(emb_sizes, n_cont, layer_sizes, conv_layers, embed_p,ps)\n",
    "\n",
    "learn = Learner(dls,model, loss_func=rmspe, splitter = split_2way, metrics=AccumMetric(rmspe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d90f504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.006272</td>\n",
       "      <td>1.097288</td>\n",
       "      <td>1.130351</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.282102</td>\n",
       "      <td>0.258605</td>\n",
       "      <td>0.261311</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>0.239671</td>\n",
       "      <td>0.242579</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rmspe</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.236532</td>\n",
       "      <td>0.239357</td>\n",
       "      <td>0.241689</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.233727</td>\n",
       "      <td>0.238698</td>\n",
       "      <td>0.240847</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.249712</td>\n",
       "      <td>0.238347</td>\n",
       "      <td>0.240588</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.230479</td>\n",
       "      <td>0.232774</td>\n",
       "      <td>0.235170</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.232515</td>\n",
       "      <td>0.242215</td>\n",
       "      <td>0.244570</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.234777</td>\n",
       "      <td>0.236301</td>\n",
       "      <td>0.238351</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.237893</td>\n",
       "      <td>0.238184</td>\n",
       "      <td>0.240341</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.246414</td>\n",
       "      <td>0.227909</td>\n",
       "      <td>0.230345</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.235773</td>\n",
       "      <td>0.238071</td>\n",
       "      <td>0.240118</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.232565</td>\n",
       "      <td>0.230037</td>\n",
       "      <td>0.232628</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.234359</td>\n",
       "      <td>0.236961</td>\n",
       "      <td>0.239467</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.236705</td>\n",
       "      <td>0.228899</td>\n",
       "      <td>0.231823</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.248079</td>\n",
       "      <td>0.239456</td>\n",
       "      <td>0.245369</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.237179</td>\n",
       "      <td>0.232845</td>\n",
       "      <td>0.237027</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.237254</td>\n",
       "      <td>0.239005</td>\n",
       "      <td>0.242535</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.237267</td>\n",
       "      <td>0.230807</td>\n",
       "      <td>0.234592</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.226547</td>\n",
       "      <td>0.228553</td>\n",
       "      <td>0.231572</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.226675</td>\n",
       "      <td>0.224367</td>\n",
       "      <td>0.227661</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.228401</td>\n",
       "      <td>0.230193</td>\n",
       "      <td>0.233191</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.226424</td>\n",
       "      <td>0.226333</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.233725</td>\n",
       "      <td>0.233675</td>\n",
       "      <td>0.237101</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.221091</td>\n",
       "      <td>0.229033</td>\n",
       "      <td>0.231094</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.221795</td>\n",
       "      <td>0.225305</td>\n",
       "      <td>0.227428</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.219891</td>\n",
       "      <td>0.226223</td>\n",
       "      <td>0.228082</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.220947</td>\n",
       "      <td>0.230766</td>\n",
       "      <td>0.233463</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.221246</td>\n",
       "      <td>0.236681</td>\n",
       "      <td>0.242585</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.218790</td>\n",
       "      <td>0.583104</td>\n",
       "      <td>2.449778</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.220082</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>2.087895</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.219481</td>\n",
       "      <td>0.685064</td>\n",
       "      <td>2.748881</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.218401</td>\n",
       "      <td>0.225620</td>\n",
       "      <td>0.227812</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.217482</td>\n",
       "      <td>0.224210</td>\n",
       "      <td>0.228384</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.217540</td>\n",
       "      <td>0.231063</td>\n",
       "      <td>0.242408</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.218421</td>\n",
       "      <td>0.447118</td>\n",
       "      <td>2.085995</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.216748</td>\n",
       "      <td>0.223386</td>\n",
       "      <td>0.227388</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.216971</td>\n",
       "      <td>0.232115</td>\n",
       "      <td>0.234265</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.215971</td>\n",
       "      <td>0.220466</td>\n",
       "      <td>0.222450</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.217383</td>\n",
       "      <td>0.222231</td>\n",
       "      <td>0.224514</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.216392</td>\n",
       "      <td>0.224371</td>\n",
       "      <td>0.226408</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.215200</td>\n",
       "      <td>0.224005</td>\n",
       "      <td>0.225929</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.214695</td>\n",
       "      <td>0.225112</td>\n",
       "      <td>0.227086</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.215187</td>\n",
       "      <td>0.226733</td>\n",
       "      <td>0.228931</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.214969</td>\n",
       "      <td>0.221379</td>\n",
       "      <td>0.223528</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.211693</td>\n",
       "      <td>0.222723</td>\n",
       "      <td>0.224701</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.212409</td>\n",
       "      <td>0.223727</td>\n",
       "      <td>0.225705</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.213515</td>\n",
       "      <td>0.223360</td>\n",
       "      <td>0.225407</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.212626</td>\n",
       "      <td>0.222066</td>\n",
       "      <td>0.224080</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.212236</td>\n",
       "      <td>0.219995</td>\n",
       "      <td>0.221996</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.211858</td>\n",
       "      <td>0.220192</td>\n",
       "      <td>0.222195</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.213650</td>\n",
       "      <td>0.223139</td>\n",
       "      <td>0.225066</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.212133</td>\n",
       "      <td>0.228037</td>\n",
       "      <td>0.229948</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(50,5e-3, freeze_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b67947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python38564bitfastaicondad52d12c5a30a4725bf9d3e235cf1271c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
